{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "549d14426afb2109edb71ef6e0223d5b",
     "grade": false,
     "grade_id": "cell-133a4667b3e842fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Offline and Online Learning to Rank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T23:48:08.415872Z",
     "start_time": "2021-03-11T23:48:06.746105Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7be29958190a403c77402e97c21c5252",
     "grade": false,
     "grade_id": "cell-b08a635cb01047dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import itertools\n",
    "from argparse import Namespace\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import dataset\n",
    "import evaluate\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8f126271fe03e0c82c752179a1293748",
     "grade": false,
     "grade_id": "cell-ef602d983baa9d90",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Offline LTR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T23:48:09.981591Z",
     "start_time": "2021-03-11T23:48:08.416870Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e11c95b755f0b252276313365c6ff290",
     "grade": false,
     "grade_id": "cell-d4779843ecb42649",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dataset.download_dataset()\n",
    "data = dataset.get_dataset()\n",
    "# there is only 1 fold for this dataset \n",
    "data = data.get_data_folds()[0]\n",
    "# read in the data\n",
    "data.read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T23:48:09.997659Z",
     "start_time": "2021-03-11T23:48:09.981591Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8008b140d6012489be5056ec30e90444",
     "grade": false,
     "grade_id": "cell-2a79356db5683374",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 501\n",
      "Split: train\n",
      "\tNumber of queries 2735\n",
      "\tNumber of docs 85227\n",
      "Split: validation\n",
      "\tNumber of queries 403\n",
      "\tNumber of docs 12794\n",
      "Split: test\n",
      "\tNumber of queries 949\n",
      "\tNumber of docs 29881\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of features: {data.num_features}\")\n",
    "# print some statistics\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    print(f\"Split: {split}\")\n",
    "    split = getattr(data, split)\n",
    "    print(f\"\\tNumber of queries {split.num_queries()}\")\n",
    "    print(f\"\\tNumber of docs {split.num_docs()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T23:48:10.026315Z",
     "start_time": "2021-03-11T23:48:09.999653Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb52800727e7a5fe81c92706c34e6471",
     "grade": false,
     "grade_id": "cell-4ad2f0d8e4f66d37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# these is a useful class to create torch DataLoaders, and can be used during training\n",
    "class LTRData(Dataset):\n",
    "    def __init__(self, data, split):\n",
    "        split = {\n",
    "            \"train\": data.train,\n",
    "            \"validation\": data.validation,\n",
    "            \"test\": data.test\n",
    "        }.get(split)\n",
    "        assert split is not None, \"Invalid split!\"\n",
    "        features, labels = split.feature_matrix, split.label_vector\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.labels = torch.FloatTensor(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.features.size(0)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.features[i], self.labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T23:48:10.136360Z",
     "start_time": "2021-03-11T23:48:10.122398Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ca1e81dd1f55111cda0a04093fd223b",
     "grade": false,
     "grade_id": "cell-b66759e20b89e0b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this function evaluates a model, on a given split\n",
    "def evaluate_model(pred_fn, split, batch_size=256, print_results=False, q_level=False):\n",
    "    dl = DataLoader(LTRData(data, split), batch_size=batch_size)\n",
    "    all_scores = []\n",
    "    all_labels = []\n",
    "    for (x, y) in tqdm(dl, desc=f'Eval ({split})', leave=False):\n",
    "        all_labels.append(y.squeeze().numpy())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = pred_fn(x)\n",
    "            all_scores.append(output.squeeze().numpy())\n",
    "            \n",
    "    split = {\n",
    "            \"train\": data.train,\n",
    "            \"validation\": data.validation,\n",
    "            \"test\": data.test\n",
    "    }.get(split)   \n",
    "    results = evaluate.evaluate2(np.asarray(all_scores), np.asarray(all_labels), print_results=print_results, q_level=q_level)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T23:48:10.735757Z",
     "start_time": "2021-03-11T23:48:10.722792Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d81a93ddde3c0ae3be42eba5a6ba025d",
     "grade": false,
     "grade_id": "cell-df3d4a5ebf6dece6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# use to get reproducible results\n",
    "def seed(random_seed):\n",
    "    import random\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "acd2f7fa9d402a7704d9f7f5fc1c2c89",
     "grade": false,
     "grade_id": "cell-a29483034efce729",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Pointwise LTR \n",
    "\n",
    "Let $x \\in \\mathbb{R}^d$ be an input feature vector, containing features for a query-document pair. Let $f: \\mathbb{R}^d \\rightarrow \\mathbb{R} $ be a function that maps this feature vector to a number $f(x)$ - either a relevance score (regression) or label (classification). The data $\\{x \\}$ are treated as feature vectors and the relevance judgements are treated as the target which we want to predict. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T23:48:10.750717Z",
     "start_time": "2021-03-11T23:48:10.737752Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cbaeb826028de6d6d7429ee18c90f455",
     "grade": false,
     "grade_id": "cell-e6ebad1d98f78bf0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class NeuralModule(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(in_features=501, out_features=256),\n",
    "                                 nn.ReLU(),\n",
    "                                nn.Linear(in_features=256, out_features=output_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Takes in an input feature vector (of size 501) and produces the (regression/classification) output \n",
    "        Input: x: a [N, 501] tensor\n",
    "        Output: a [N, output_dim] tensor\n",
    "        \"\"\"\n",
    "        out = self.net(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T23:48:10.766674Z",
     "start_time": "2021-03-11T23:48:10.752712Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eebff5ba2f470a05674e79514a6ba7bc",
     "grade": false,
     "grade_id": "cell-2326178594a8f44c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "point_nn_clf = NeuralModule(5)\n",
    "point_nn_reg = NeuralModule(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation :**\n",
    "Implement cross entropy loss and and then cross entropy prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T23:48:10.837656Z",
     "start_time": "2021-03-11T23:48:10.829506Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a82ac14d42f8800a3fcf1fe5153dd1d3",
     "grade": false,
     "grade_id": "cell-d095f3c75bd11bc3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def clf_loss(output, target):\n",
    "    assert output.size(0) == target.size(0)\n",
    "    assert output.size(1) == 5\n",
    "    target = target.long()\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    out = loss(output, target)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T23:48:10.891815Z",
     "start_time": "2021-03-11T23:48:10.869134Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c1e1871d067d534d41585fe9d657244a",
     "grade": false,
     "grade_id": "cell-d01649f26022bf4c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def clf_pred(inp, net):\n",
    "    features = net(inp)\n",
    "    out = features.max(dim=1)[1] \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T23:48:10.938940Z",
     "start_time": "2021-03-11T23:48:10.924977Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6cf6191b552e4daea3f0fd4a91e15fd4",
     "grade": false,
     "grade_id": "cell-a4f04b744ef63756",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "clf_pred_fn = partial(clf_pred, net=point_nn_clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e14973fb674e1e9adb553605e4e7b333",
     "grade": false,
     "grade_id": "cell-d683efd6ca306e81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Implementation :**\n",
    "Implement regression loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T23:48:10.954316Z",
     "start_time": "2021-03-11T23:48:10.939937Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f2b905ddb927ed981bb294825674993",
     "grade": false,
     "grade_id": "cell-c024ed97d7100038",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def reg_loss(output, target):\n",
    "    assert target.dim() == 1\n",
    "    assert output.size(0) == target.size(0)\n",
    "    assert output.size(1) == 1\n",
    "        target = torch.unsqueeze(target, 1)\n",
    "    loss = nn.MSELoss()\n",
    "    out = loss(output, target)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T23:48:11.004969Z",
     "start_time": "2021-03-11T23:48:10.982327Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8dbfd2a686ecc7ab254a4e5e9b332119",
     "grade": false,
     "grade_id": "cell-9361533c572e304b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_pointwise(net, loss, params):\n",
    "    \"\"\"\n",
    "    This function should train a Pointwise network, \n",
    "    trained based on the loss (either \"clf\" / \"reg\"). \n",
    "    \n",
    "    The network is trained using the Adam optimizer\n",
    "        \n",
    "    net: the neural network to be trained\n",
    "    \n",
    "    loss: one of \"clf\" or \"reg\"\n",
    "    \n",
    "    params: params is an object which contains config used in training \n",
    "        (eg. params.epochs - the number of epochs to train). \n",
    "    \n",
    "    Returns: a dictionary containing: \"metrics_val\" (a list of dictionaries) and \n",
    "             \"metrics_train\" (a list of dictionaries). \n",
    "             \n",
    "             \"metrics_val\" should contain metrics (the metrics in params.metrics) computed\n",
    "             after each epoch on the validation set (metrics_train is similar). \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    assert loss in {\"clf\", \"reg\"}\n",
    "    \n",
    "    val_metrics_epoch = []\n",
    "    train_metrics_epoch = []\n",
    "    train_dl = DataLoader(LTRData(data, \"train\"), batch_size=params.batch_size, shuffle=True)\n",
    "    optimiser = Adam(net.parameters(), lr=params.lr)\n",
    "    net.train()\n",
    "    for i in range(params.epochs):\n",
    "        for (x, y) in train_dl:\n",
    "            optimiser.zero_grad()\n",
    "            outputs = net(x)\n",
    "            if loss == 'clf':\n",
    "                loss_value = clf_loss(outputs, y)\n",
    "            elif loss == 'reg':\n",
    "                loss_value = reg_loss(outputs, y)\n",
    "            loss_value.backward()\n",
    "            optimiser.step()\n",
    "        if loss == 'clf':\n",
    "            clf_pred_fn = partial(clf_pred, net=net)         \n",
    "            dict_epoch_train = {}\n",
    "            dict_values_train = evaluate_model(clf_pred_fn, \"train\", print_results=False)\n",
    "            select_m_train = {k: v for (k, v) in dict_values_train.items() if k in params.metrics}\n",
    "            dict_epoch_train[f'Epoch {i+1}'] = select_m_train\n",
    "            train_metrics_epoch.append(dict_epoch_train)\n",
    "            dict_epoch_eval = {}\n",
    "            dict_values_eval = evaluate_model(clf_pred_fn, \"validation\", print_results=False)\n",
    "            select_m_eval = {k: v for (k, v) in dict_values_eval.items() if k in params.metrics}\n",
    "            dict_epoch_eval[f'Epoch {i+1}'] = select_m_eval\n",
    "            val_metrics_epoch.append(dict_epoch_eval) \n",
    "        elif loss == 'reg':\n",
    "            dict_epoch_train = {}\n",
    "            dict_values_train = evaluate_model(net, \"train\", print_results=False)\n",
    "            select_m_train = {k: v for (k, v) in dict_values_train.items() if k in params.metrics}\n",
    "            dict_epoch_train[f'Epoch {i+1}'] = select_m_train\n",
    "            train_metrics_epoch.append(dict_epoch_train)\n",
    "            dict_epoch_eval = {}\n",
    "            dict_values_eval = evaluate_model(net, \"validation\", print_results=False)\n",
    "            select_m_eval = {k: v for (k, v) in dict_values_eval.items() if k in params.metrics}\n",
    "            dict_epoch_eval[f'Epoch {i+1}'] = select_m_eval\n",
    "            val_metrics_epoch.append(dict_epoch_eval)\n",
    "                  \n",
    "    return {\n",
    "        \"metrics_val\": val_metrics_epoch,\n",
    "        \"metrics_train\": train_metrics_epoch\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T23:48:11.020590Z",
     "start_time": "2021-03-11T23:48:11.004969Z"
    }
   },
   "outputs": [],
   "source": [
    "pointwise_test_params = Namespace(epochs=2, \n",
    "                    lr=1e-3,\n",
    "                    batch_size=256,\n",
    "                   metrics={\"ndcg\"})\n",
    "##train a regression model\n",
    "met_reg = train_pointwise(point_nn_reg, \"reg\", pointwise_test_params)\n",
    "## train a classification model\n",
    "met_clf = train_pointwise(point_nn_clf, \"clf\", pointwise_test_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed8a82c097df5799c15c9000475ad11e",
     "grade": false,
     "grade_id": "cell-e48bb26c37eacea9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Pairwise LTR\n",
    "\n",
    "For a given query, consider two documents $D_i$ and $D_j$ with two different ground truth relevance  labels,  with  feature  vectors $x_i$ and $x_j$ respectively.   The  RankNet  model,  just  like  the pointwise model, uses $f$ to predict scores i.e $s_i=f(x_i)$ and $s_j=f(x_j)$, but uses a different loss during  training. $D_i \\triangleright D_j$ denotes  the  event  that $D_i$ should  be  ranked  higher  than $D_j$.   The  two outputs $s_i$ and $s_j$ are mapped to a learned probability that $D_i \\triangleright D_j$: \n",
    "\n",
    "\n",
    "$$        P_{ij} = \\frac{1}{1 + e^{-\\sigma(s_i - s_j)}} $$\n",
    "  \n",
    "where $\\sigma$ is a parameter that determines the shape of the sigmoid. The loss of the RankNet model is the cross entropy cost function:\n",
    "\n",
    "$$        C = - \\bar{P}_{ij} \\log P_{ij} - (1-\\bar{P}_{ij}) \\log (1 - P_{ij}) $$\n",
    "\n",
    "As the name suggests, in the pairwise approach to LTR, we optimize a loss $l$ over pairs of documents. Let $S_{ij} \\in \\{0, \\pm1 \\}$ be equal to $1$ if the relevance of document $i$ is greater than document $j$; $-1$ if document $j$ is more relevant than document $i$; and 0 if they have the same relevance. This gives us $\\bar{P}_{ij} = \\frac{1}{2} (1 + S_{ij})$ so that $\\bar{P}_{ij} = 1$ if $D_i \\triangleright D_j$; $\\bar{P}_{ij} = 0$ if $D_j \\triangleright D_i$; and finally $\\bar{P}_{ij} = \\frac{1}{2}$ if the relevance is identical. This gives us:\n",
    "\n",
    "$$        C = \\frac{1}{2}(1- S_{ij})\\sigma(s_i - s_j) + \\log(1+ e^{-\\sigma(s_i - s_j)}) $$\n",
    "\n",
    "Now, consider a single query for which $n$ documents have been returned. Let the output scores of the ranker be $s_j$ ; $j=\\{1, \\dots, n \\}$, the model parameters be $w_k \\in \\mathbb{R}^W$, and let the set of pairs of document indices used for training be $\\mathcal{P}$. Then, the total cost is $C_T = \\sum_{i,j \\in \\mathcal{P}} C(s_i; s_j)$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T23:50:08.301680Z",
     "start_time": "2021-03-11T23:50:08.257799Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e50a3b3ef0bf4fba2f792073ebb8443",
     "grade": false,
     "grade_id": "cell-0009b5254fc5f2ad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class QueryGroupedLTRData(Dataset):\n",
    "    def __init__(self, data, split):\n",
    "        self.split = {\n",
    "            \"train\": data.train,\n",
    "            \"validation\": data.validation,\n",
    "            \"test\": data.test\n",
    "        }.get(split)\n",
    "        assert self.split is not None, \"Invalid split!\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.split.num_queries()\n",
    "\n",
    "    def __getitem__(self, q_i):\n",
    "        feature = torch.FloatTensor(self.split.query_feat(q_i))\n",
    "        labels = torch.FloatTensor(self.split.query_labels(q_i))\n",
    "        return q_i, feature, labels\n",
    "\n",
    "def qg_collate_fn(batch):\n",
    "    \n",
    "    qids = []\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for (q, f, l) in batch:\n",
    "        qids.append(q)\n",
    "        features.append(f)\n",
    "        labels.append(l)\n",
    "    \n",
    "    return qids, features, labels\n",
    "    \n",
    "    train_dl = DataLoader(QueryGroupedLTRData(data, \"train\"), batch_size=1, shuffle=True, collate_fn=qg_collate_fn)\n",
    "for (qids, x, y) in train_dl:\n",
    "    for q_i, features_i, labels_i in zip(qids, x, y):\n",
    "        print(f\"Query {q_i} has {len(features_i)} query-document pairs\")\n",
    "        print(f\"Shape of features for Query {q_i}: {features_i.size()}\")\n",
    "        break\n",
    "    break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T23:50:08.326523Z",
     "start_time": "2021-03-11T23:50:08.303675Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3dcefb2b21b4524aa03cdf22382934ba",
     "grade": false,
     "grade_id": "cell-3a612aeb9e982639",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def pairwise_loss(scores, labels):\n",
    "    if labels.size(0) < 2:\n",
    "        return None\n",
    "    n = scores.size(0)\n",
    "    if scores.size() != (n,1):\n",
    "        scores = torch.unsqueeze(scores, 1)\n",
    "    distances = scores - torch.transpose(scores, 0, 1)\n",
    "    expand_labels = torch.unsqueeze(labels, 1)\n",
    "    diff_labels = expand_labels - torch.transpose(expand_labels, 0, 1)\n",
    "    pos = (diff_labels > 0) * torch.ones(n)\n",
    "    neg = (diff_labels < 0) * (-torch.ones(n))\n",
    "    S_ij = pos + neg\n",
    "    loss_per_pair = 0.5 * (1 - S_ij) * distances + torch.log(1 + torch.exp(-distances))\n",
    "    loss_per_pair = loss_per_pair.masked_select(~torch.eye(n, dtype=bool)).view(n, n - 1)\n",
    "    final_loss = torch.mean(loss_per_pair)\n",
    "    return final_loss\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T23:50:08.409787Z",
     "start_time": "2021-03-11T23:50:08.394166Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31ad65b3cbd923af54ff56f804bbc93c",
     "grade": false,
     "grade_id": "cell-a85c38ca94031203",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_pairwise(net, params):\n",
    "    \"\"\"\n",
    "    This function should train the given network using the pairwise loss\n",
    "    \n",
    "    Returns: a dictionary containing: \"metrics_val\" (a list of dictionaries) and \n",
    "             \"metrics_train\" (a list of dictionaries). \n",
    "             \n",
    "             \"metrics_val\" should contain metrics (the metrics in params.metrics) computed\n",
    "             after each epoch on the validation set (metrics_train is similar). \n",
    "\n",
    "    Hint: Consider the case when the loss function returns 'None'\n",
    "    \n",
    "    net: the neural network to be trained\n",
    "    \n",
    "    params: params is an object which contains config used in training \n",
    "        (eg. params.epochs - the number of epochs to train). \n",
    "    \"\"\"\n",
    "\n",
    "    val_metrics_epoch = []\n",
    "    train_metrics_epoch = []\n",
    "    train_dl = DataLoader(QueryGroupedLTRData(data, \"train\"), batch_size=1, shuffle=True, collate_fn=qg_collate_fn)\n",
    "    optimiser = Adam(net.parameters(), lr=params.lr)\n",
    "    net.train()\n",
    "    for i in range(params.epochs):\n",
    "        for (qids, x, y) in train_dl:\n",
    "            for q_i, features_i, labels_i in zip(qids, x, y):\n",
    "                optimiser.zero_grad()\n",
    "                outputs = net(features_i)\n",
    "                loss_value = pairwise_loss(outputs, labels_i)\n",
    "                loss_value.backward()\n",
    "                optimiser.step()\n",
    "                    \n",
    "        dict_epoch_train = {}\n",
    "        dict_values_train = evaluate_model(net, \"train\", print_results=False)\n",
    "        select_m_train = {k: v for (k, v) in dict_values_train.items() if k in params.metrics}\n",
    "        dict_epoch_train[f'Epoch {i+1}'] = select_m_train\n",
    "        train_metrics_epoch.append(dict_epoch_train)\n",
    "        dict_epoch_eval = {}\n",
    "        dict_values_eval = evaluate_model(net, \"validation\", print_results=False)\n",
    "        select_m_eval = {k: v for (k, v) in dict_values_eval.items() if k in params.metrics}\n",
    "        dict_epoch_eval[f'Epoch {i+1}'] = select_m_eval\n",
    "        val_metrics_epoch.append(dict_epoch_eval) \n",
    "                                        \n",
    "    return {\n",
    "        \"metrics_val\": val_metrics_epoch,\n",
    "        \"metrics_train\": train_metrics_epoch\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3867bfe2e108bffb3ae69f5ddfd68834",
     "grade": false,
     "grade_id": "cell-3a95bb01f72fc76c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Pairwise: Speed-up RankNet\n",
    "\n",
    "\n",
    "To speed up training of the previous model, we can consider a sped up version of the model, where instead of `.backward` on the loss, we use `torch.backward(lambda_i)`. \n",
    "\n",
    "The derivative of the total cost $C_T$ with respect to the model parameters $w_k$ is:\n",
    "\n",
    "$$        \\frac{\\partial C_T}{\\partial w_k} = \\sum_{(i,j) \\in \\mathcal{P}} \\frac{\\partial C(s_i, s_j)}{\\partial s_i} \\frac{\\partial s_i}{\\partial w_k} + \\frac{\\partial C(s_i, s_j)}{\\partial s_j} \\frac{\\partial s_j}{\\partial w_k} $$\n",
    "\n",
    "We can rewrite this sum by considering the set of indices $j$ , for which $\\{i,j\\}$ is a valid pair, denoted by $\\mathcal{P}_i$, and the set of document indices $\\mathcal{D}$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial C_T}{\\partial w_k} = \\sum_{i \\in \\mathcal{D}}\n",
    "\\frac{\\partial s_i}{\\partial w_k} \\sum_{j \\in \\mathcal{P}_i} \n",
    "\\frac{\\partial C(s_i, s_j)}{\\partial s_i} \n",
    "$$\n",
    "\n",
    "This sped of version of the algorithm first computes scores $s_i$ for all the documents. Then for each $j= 1, \\dots, n$, compute:\n",
    "\n",
    "$$\n",
    "\\lambda_{ij} = \\frac{\\partial C(s_i, s_j)}{\\partial s_i} = \\sigma \\bigg( \\frac{1}{2}(1 - S_{ij}) -  \\frac{1}{1 + e^{\\sigma(s_i -s_j))}} \\bigg) \\\\\n",
    "\\lambda_i = \\sum_{j \\in \\mathcal{P}_i} \\frac{\\partial C(s_i, s_j)}{\\partial s_i} = \\sum_{j \\in \\mathcal{P}_i} \\lambda_{ij}\n",
    "$$\n",
    "\n",
    "That gives us:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial C_T}{\\partial w_k} = \\sum_{i \\in \\mathcal{D}}\n",
    "\\frac{\\partial s_i}{\\partial w_k} \\lambda_i\n",
    "$$\n",
    "\n",
    "This can be directly optimized in pytorch using: `torch.autograd.backward(scores, lambda_i)` \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T23:50:08.462789Z",
     "start_time": "2021-03-11T23:50:08.447847Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4cea38cdd68cb70d08e33827bffc53a8",
     "grade": false,
     "grade_id": "cell-ba7f8d8631e3f1d6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_lambda_i(scores, labels):\n",
    "    \"\"\"\n",
    "    Compute \\lambda_i (defined in the previous cell). (assume sigma=1.)\n",
    "    \n",
    "    scores: tensor of size [N, 1] (the output of a neural network), where N = length of <query, document> pairs\n",
    "    labels: tensor of size [N], contains the relevance labels \n",
    "    \n",
    "    return: \\lambda_i, a tensor of shape: [N, 1]\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    n = scores.size(0)\n",
    "    if scores.size() != (n,1):\n",
    "        scores = torch.unsqueeze(scores, 1)\n",
    "    distances = scores - torch.transpose(scores, 0, 1)\n",
    "    expand_labels = torch.unsqueeze(labels, 1)\n",
    "    diff_labels = expand_labels - torch.transpose(expand_labels, 0, 1)\n",
    "    pos = (diff_labels > 0) * torch.ones(n)\n",
    "    neg = (diff_labels < 0) * (-torch.ones(n))\n",
    "    S_ij = pos + neg\n",
    "    lambda_i = 0.5 * (1 - S_ij) - (1 / (1 + torch.exp(distances)))\n",
    "    lambda_i = torch.sum(lambda_i, dim=1, keepdim=True)\n",
    "    return lambda_i\n",
    "\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T23:50:08.530159Z",
     "start_time": "2021-03-11T23:50:08.506382Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "14e4da9878b2e0a3603437b29a66a07c",
     "grade": false,
     "grade_id": "cell-ddfeb927c2f4a31c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_pairwise_spedup(net, params):\n",
    "    \"\"\"\n",
    "    This function should train the given network using the sped up pairwise loss\n",
    "    \n",
    "    net: the neural network to be trained\n",
    "    \n",
    "    params: params is an object which contains config used in training \n",
    "        (eg. params.epochs - the number of epochs to train). \n",
    "    \n",
    "    Returns: a dictionary containing: \"metrics_val\" (a list of dictionaries) and \n",
    "             \"metrics_train\" (a list of dictionaries). \n",
    "             \n",
    "             \"metrics_val\" should contain metrics (the metrics in params.metrics) computed\n",
    "             after each epoch on the validation set (metrics_train is similar). \n",
    "    \"\"\"\n",
    "    \n",
    "    val_metrics_epoch = []\n",
    "    train_metrics_epoch = []\n",
    "\n",
    "        \n",
    "    train_dl = DataLoader(QueryGroupedLTRData(data, \"train\"), batch_size=1, shuffle=True, collate_fn=qg_collate_fn)\n",
    "    optimiser = Adam(net.parameters(), lr=params.lr)\n",
    "    net.train()\n",
    "    for i in range(params.epochs):\n",
    "        for (qids, x, y) in train_dl:\n",
    "            for q_i, features_i, labels_i in zip(qids, x, y):\n",
    "                optimiser.zero_grad()\n",
    "                outputs = net(features_i)\n",
    "                lambda_i = compute_lambda_i(outputs, labels_i)\n",
    "                torch.autograd.backward(outputs, lambda_i)\n",
    "                optimiser.step()\n",
    "        \n",
    "        dict_epoch_train = {}\n",
    "        dict_values_train = evaluate_model(net, \"train\", print_results=False)\n",
    "        select_m_train = {k: v for (k, v) in dict_values_train.items() if k in params.metrics}\n",
    "        dict_epoch_train[f'Epoch {i+1}'] = select_m_train\n",
    "        train_metrics_epoch.append(dict_epoch_train)\n",
    "        dict_epoch_eval = {}\n",
    "        dict_values_eval = evaluate_model(net, \"validation\", print_results=False)\n",
    "        select_m_eval = {k: v for (k, v) in dict_values_eval.items() if k in params.metrics}\n",
    "        dict_epoch_eval[f'Epoch {i+1}'] = select_m_eval\n",
    "        val_metrics_epoch.append(dict_epoch_eval)  \n",
    "    \n",
    "    return {\n",
    "        \"metrics_val\": val_metrics_epoch,\n",
    "        \"metrics_train\": train_metrics_epoch\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T23:50:08.545781Z",
     "start_time": "2021-03-11T23:50:08.530159Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb9b27b6ec712d8d1146751bc150791e",
     "grade": false,
     "grade_id": "cell-f80dc2eae24968ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pairwise_spedup_params_test = Namespace(epochs=1, lr=1e-3, batch_size=1, metrics={\"ndcg@10\",\"ndcg\"})\n",
    "pairwise_net_spedup = NeuralModule(1)\n",
    "train_pairwise_spedup(pairwise_net_spedup, pairwise_spedup_params_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "60ad8126d68fcf4814988ad22c335c2a",
     "grade": false,
     "grade_id": "cell-14e048f55b2e6aea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Listwise LTR\n",
    " Given a ranking measure $IRM$, such as $NDCG$ or $ERR$, the lambda function in LambdaRank is defined as:\n",
    "\n",
    "\n",
    "$$        \\frac{\\partial C}{\\partial s_i} = \\sum_{j \\in D} \\lambda_{ij} \\cdot |\\bigtriangleup IRM (i,j)| $$\n",
    "\n",
    "Where $|\\bigtriangleup IRM(i,j)|$ is the absolute difference in $IRM$ after swapping the rank positions $r_i$ and $r_j$ while leaving everything else unchanged ($| \\cdot |$ denotes the absolute value). Note that we do not backpropogate $|\\bigtriangleup IRM|$, it is treated as a constant that scales the gradients. In this assignment we will use $|\\bigtriangleup NDCG|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T23:51:54.172310Z",
     "start_time": "2021-03-11T23:51:54.157348Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0ba4266e951c80236d3dc6f0e0c32a5",
     "grade": false,
     "grade_id": "cell-48f6a2a1c4a529b6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def listwise_loss(scores, labels):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute the LambdaRank loss. (assume sigma=1.)\n",
    "    \n",
    "    scores: tensor of size [N, 1] (the output of a neural network), where N = length of <query, document> pairs\n",
    "    labels: tensor of size [N], contains the relevance labels \n",
    "    \n",
    "    returns: a tensor of size [N, 1]\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    n = scores.size(0)\n",
    "    if scores.size() != (n,1):\n",
    "        scores = torch.unsqueeze(scores, 1)\n",
    "\n",
    "    random_i = np.random.permutation(np.arange(np.asarray(scores.detach()).shape[0]))\n",
    "    labels_np = np.asarray(labels.detach())[random_i]\n",
    "    scores_np = np.asarray(scores.flatten().detach())[random_i]\n",
    "    sort_ind = np.argsort(scores_np)[::-1]\n",
    "    sorted_labels = labels_np[sort_ind]\n",
    "    ideal_labels = np.sort(labels_np)[::-1]\n",
    "    epsilon = 0.00000000001 \n",
    "    idcg = evaluate.dcg_at_k(ideal_labels, 0)\n",
    "    idcg = 1.0 / (idcg + epsilon) #We add epsilon so that when idcg = 0 (when all labels are zero) we don't divide by zero\n",
    "    \n",
    "    k = sorted_labels.shape[0]\n",
    "    order_rank = torch.arange(k).view(-1, 1)\n",
    "    sorted_labels2 = torch.unsqueeze(torch.from_numpy(sorted_labels), 1)\n",
    "    nom_diff = torch.pow(2.0, sorted_labels2) - torch.pow(2.0, torch.transpose(sorted_labels2, 0, 1))\n",
    "    denom_diff = (1.0 / torch.log2(order_rank + 2.0)) - (1.0 / torch.log2(order_rank.t() + 2.0))\n",
    "    delta_ndcg = torch.abs(idcg * nom_diff * denom_diff)\n",
    "\n",
    "    distances = scores - torch.transpose(scores, 0, 1)\n",
    "    expand_labels = torch.unsqueeze(labels, 1)\n",
    "    diff_labels = expand_labels - torch.transpose(expand_labels, 0, 1)\n",
    "    pos = (diff_labels > 0) * torch.ones(n)\n",
    "    neg = (diff_labels < 0) * (-torch.ones(n))\n",
    "    S_ij = pos + neg\n",
    "    lambda_i = 0.5 * (1 - S_ij) - (1 / (1 + torch.exp(distances)))\n",
    "\n",
    "    lambda_r = lambda_i * delta_ndcg\n",
    "    lambda_r = torch.sum(lambda_r, dim=1, keepdim=True)\n",
    "    return lambda_r    \n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T23:51:54.243487Z",
     "start_time": "2021-03-11T23:51:54.222174Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "786e51ea263d0ea82a5ec251344f7d0e",
     "grade": false,
     "grade_id": "cell-34c4d0bdbb753580",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_listwise(net, params):\n",
    "    \"\"\"\n",
    "    This function should train the given network using the listwise (LambdaRank) loss\n",
    "    \n",
    "\n",
    "    \n",
    "    net: the neural network to be trained\n",
    "    \n",
    "    params: params is an object which contains config used in training \n",
    "        (eg. params.epochs - the number of epochs to train). \n",
    "        \n",
    "    Returns: a dictionary containing: \"metrics_val\" (a list of dictionaries) and \n",
    "             \"metrics_train\" (a list of dictionaries). \n",
    "             \n",
    "             \"metrics_val\" should contain metrics (the metrics in params.metrics) computed\n",
    "             after each epoch on the validation set (metrics_train is similar). \n",
    "    \"\"\"\n",
    "    \n",
    "    val_metrics_epoch = []\n",
    "    train_metrics_epoch = []\n",
    "    train_dl = DataLoader(QueryGroupedLTRData(data, \"train\"), batch_size=1, shuffle=True, collate_fn=qg_collate_fn)\n",
    "    optimiser = Adam(net.parameters(), lr=params.lr)\n",
    "    net.train()\n",
    "    for i in range(params.epochs):\n",
    "        for (qids, x, y) in train_dl:\n",
    "            for q_i, features_i, labels_i in zip(qids, x, y):\n",
    "                optimiser.zero_grad()\n",
    "                outputs = net(features_i)\n",
    "                loss = listwise_loss(outputs, labels_i)\n",
    "                torch.autograd.backward(outputs, loss)\n",
    "                optimiser.step()\n",
    "                    \n",
    "        dict_epoch_train = {}\n",
    "        dict_values_train = evaluate_model(net, \"train\", print_results=False)\n",
    "        select_m_train = {k: v for (k, v) in dict_values_train.items() if k in params.metrics}\n",
    "        dict_epoch_train[f'Epoch {i+1}'] = select_m_train\n",
    "        train_metrics_epoch.append(dict_epoch_train)\n",
    "        dict_epoch_eval = {}\n",
    "        dict_values_eval = evaluate_model(net, \"validation\", print_results=False)\n",
    "        select_m_eval = {k: v for (k, v) in dict_values_eval.items() if k in params.metrics}\n",
    "        dict_epoch_eval[f'Epoch {i+1}'] = select_m_eval\n",
    "        val_metrics_epoch.append(dict_epoch_eval)     \n",
    "    \n",
    "    return {\n",
    "        \"metrics_val\": val_metrics_epoch,\n",
    "        \"metrics_train\": train_metrics_epoch\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-11T23:51:54.259328Z",
     "start_time": "2021-03-11T23:51:54.243487Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "109d4be0105ee65f2e446c5d1a961eea",
     "grade": false,
     "grade_id": "cell-36910488e505a73a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "listwise_params_test = Namespace(epochs=1, lr=1e-3, batch_size=1, metrics={\"ndcg\"})\n",
    "listwise_net = NeuralModule(1)\n",
    "train_listwise(listwise_net, listwise_params_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "280px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
