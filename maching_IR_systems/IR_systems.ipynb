{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "758d05f39ab671358f17858c55f7161c",
     "grade": false,
     "grade_id": "cell-c9cd9e550239e812",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Term and semantic matching\n",
    "\n",
    "- [Part 1, Term-based matching]:\n",
    "    - Learn how to load a dataset and process it.\n",
    "    - Standard IR methods (TF-IDF, BM25, QL).\n",
    "    - Evaluating IR methodss.\n",
    "- [Part 2, Semantic-based matching]:\n",
    "    - Vector-space retrieval methods (LSI, LDA).\n",
    "    - Re-ranking using LSI and LDA\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:51.514587Z",
     "start_time": "2021-02-18T08:34:49.153850Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c55bfe94ff1f564dd595547e516c4c6e",
     "grade": false,
     "grade_id": "cell-f5357fabdb9660e3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# imports \n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "from functools import partial\n",
    "\n",
    "import nltk\n",
    "import requests\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, HTML\n",
    "#from IPython.html import widgets\n",
    "from collections import namedtuple\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4ef0139c6fbc22b41520721a9275c1e1",
     "grade": false,
     "grade_id": "cell-7428e12ed184408b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "# Part 1: Term-based Matching \n",
    "\n",
    "[Back to top](#top)\n",
    "\n",
    "The CACM dataset is a collection of titles and abstracts from the journal CACM (Communication of the ACM).\n",
    "\n",
    "Table of contents:\n",
    "- [Section 1: Text Processing](#text_processing) \n",
    "- [Section 2: Indexing](#indexing) \n",
    "- [Section 3: Ranking](#ranking) \n",
    "- [Section 4: Evaluation](#evaluation) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a9050c97b011a926b9e4cf6831eff5bd",
     "grade": false,
     "grade_id": "cell-4b24825cf4ae55ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "## Section 1: Text Processing \n",
    "\n",
    "[Back to Part 1](#part1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1de1b97f9ee233ad2348359f0c158eb7",
     "grade": false,
     "grade_id": "cell-45651364e7af6d5a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The following cell downloads the dataset and unzips it to a local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:51.561219Z",
     "start_time": "2021-02-18T08:34:51.514587Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d43c9ad6e77cc01ce4cef0c34824930",
     "grade": false,
     "grade_id": "cell-bbc3030bb3fe7e02",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def download_dataset():\n",
    "    folder_path = os.environ.get(\"IR1_DATA_PATH\")\n",
    "    if not folder_path:\n",
    "        folder_path = \"./datasets/\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    file_location = os.path.join(folder_path, \"cacm.zip\")\n",
    "    \n",
    "    # download file if it doesn't exist\n",
    "    if not os.path.exists(file_location):\n",
    "        \n",
    "        url = \"https://surfdrive.surf.nl/files/index.php/s/M0FGJpX2p8wDwxR/download\"\n",
    "\n",
    "        with open(file_location, \"wb\") as handle:\n",
    "            print(f\"Downloading file from {url} to {file_location}\")\n",
    "            response = requests.get(url, stream=True)\n",
    "            for data in tqdm(response.iter_content()):\n",
    "                handle.write(data)\n",
    "            print(\"Finished downloading file\")\n",
    "    \n",
    "    if not os.path.exists(os.path.join(folder_path, \"train.txt\")):\n",
    "        \n",
    "        # unzip file\n",
    "        with zipfile.ZipFile(file_location, 'r') as zip_ref:\n",
    "            zip_ref.extractall(folder_path)\n",
    "        \n",
    "download_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:51.797586Z",
     "start_time": "2021-02-18T08:34:51.783624Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45fef5d5b543ee439176d7fd0a9d20be",
     "grade": false,
     "grade_id": "cell-b736116eb419c624",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def read_cacm_docs(root_folder = \"./datasets/\"):\n",
    "    \"\"\"\n",
    "        Reads in the CACM documents. The dataset is assumed to be in the folder \"./datasets/\" by default\n",
    "        Returns: A list of 2-tuples: (doc_id, document), where 'document' is a single string created by \n",
    "            appending the title and abstract (separated by a \"\\n\"). \n",
    "            In case the record doesn't have an abstract, the document is composed only by the title\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    file_location = os.path.join(root_folder, \"cacm.all\")\n",
    "\n",
    "    doclist = []\n",
    "\n",
    "    with open(file_location, \"r\") as f:\n",
    "        docs = [(\"I\\n\" + x) for x in f.read().split(\".I \")]\n",
    "\n",
    "    docs = docs[1:]\n",
    "    docs_fields = [[\".\" + x for x in doc.split(\"\\n.\")] for doc in docs]\n",
    "\n",
    "    for doc in docs_fields:\n",
    "        abstract = \"\"\n",
    "        for field in doc:\n",
    "            if field.startswith('.I\\n') == True:\n",
    "                doc_id = field[3:]\n",
    "            elif field.startswith('.T\\n') == True:\n",
    "                title = field[3:]\n",
    "            elif field.startswith('.W\\n') == True:\n",
    "                abstract = \"\\n\" + field[3:]\n",
    "        document = title + abstract\n",
    "        doclist.append((int(doc_id), document))\n",
    "    \n",
    "    return doclist\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:51.859421Z",
     "start_time": "2021-02-18T08:34:51.799580Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70472b5c277bb7c417de8da24e4e5261",
     "grade": true,
     "grade_id": "cell-a1c43818e0d3fd79",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "docs = read_cacm_docs()\n",
    "\n",
    "assert isinstance(docs, list)\n",
    "assert len(docs) == 3204, \"There should be exactly 3024 documents\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:51.939206Z",
     "start_time": "2021-02-18T08:34:51.926243Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f98ac81b2ccb44fe3441e202e980c847",
     "grade": false,
     "grade_id": "cell-433e3ad5d0e2572a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def read_queries(root_folder = \"./datasets/\"):\n",
    "    \"\"\"\n",
    "        Reads in the CACM queries. The dataset is assumed to be in the folder \"./datasets/\" by default\n",
    "        Returns: A list of 2-tuples: (query_id, query)\n",
    "    \"\"\"\n",
    "    \n",
    "    file_location = os.path.join(root_folder, \"query.text\")\n",
    "\n",
    "    querylist = []\n",
    "\n",
    "    with open(file_location, \"r\") as f:\n",
    "        queries = [(\"I\\n\" + x) for x in f.read().split(\".I \")]\n",
    "\n",
    "    queries = queries[1:]\n",
    "    query_fields = [[\".\" + x for x in query.split(\"\\n.\")] for query in queries]\n",
    "\n",
    "    for query in query_fields:\n",
    "        for field in query:\n",
    "            if field.startswith('.I\\n') == True:\n",
    "                query_id = field[3:]\n",
    "            elif field.startswith('.W\\n') == True:\n",
    "                query_w = field[3:]\n",
    "        querylist.append((int(query_id), query_w))\n",
    "    \n",
    "    return querylist\n",
    "    \n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:52.049912Z",
     "start_time": "2021-02-18T08:34:52.035951Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6a9e9bb3ad0f8dc2ec3c497a3149092",
     "grade": false,
     "grade_id": "cell-7357aa40f64e5bcb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (1 point)\n",
    "def load_stopwords(root_folder = \"./datasets/\"):\n",
    "    \"\"\"\n",
    "        Loads the stopwords. The dataset is assumed to be in the folder \"./datasets/\" by default\n",
    "        Output: A set of stopwords\n",
    "    \"\"\"    \n",
    "    file_location = os.path.join(root_folder, \"common_words\")\n",
    "\n",
    "    with open(file_location, \"r\") as f:\n",
    "        stopwords = {x for x in f.read().lower().split(\"\\n\") if x != \"\"}\n",
    "    \n",
    "    return stopwords\n",
    "\n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:52.081826Z",
     "start_time": "2021-02-18T08:34:52.067864Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f5564d3c75bf22fbf832b3a9b938f37",
     "grade": false,
     "grade_id": "cell-322be4c9499bdc4b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "        Tokenizes the input text. Use the WordPunctTokenizer\n",
    "        Input: text - a string\n",
    "        Output: a list of tokens\n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = nltk.tokenize.WordPunctTokenizer().tokenize(text)\n",
    "    \n",
    "    return tokens\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:52.097784Z",
     "start_time": "2021-02-18T08:34:52.083855Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f60b93aa03bf9eced64940252eb33fe3",
     "grade": true,
     "grade_id": "cell-7fbf48bf7541a622",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n"
     ]
    }
   ],
   "source": [
    "text = \"the quick brown fox jumps over the lazy dog\"\n",
    "tokens = tokenize(text)\n",
    "\n",
    "assert isinstance(tokens, list)\n",
    "assert len(tokens) == 9\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:52.113741Z",
     "start_time": "2021-02-18T08:34:52.099778Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c4a6aa979d66158c7b6b992af43293a",
     "grade": false,
     "grade_id": "cell-e3f6c8e3f874b28d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def stem_token(token):\n",
    "    \"\"\"\n",
    "        Stems the given token using the PorterStemmer from the nltk library\n",
    "        Input: a single token\n",
    "        Output: the stem of the token\n",
    "    \"\"\"\n",
    "    \n",
    "    stem = nltk.stem.porter.PorterStemmer().stem(token)\n",
    "    \n",
    "    return stem\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:52.128700Z",
     "start_time": "2021-02-18T08:34:52.116734Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd2611a46e7c2e92af438d7166cf2616",
     "grade": true,
     "grade_id": "cell-cd6863e6ee6ed205",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert stem_token('owned') == 'own'\n",
    "assert stem_token('itemization') == 'item'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:52.143659Z",
     "start_time": "2021-02-18T08:34:52.130694Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ff2d215ee8e0039c5a91fd3de12e6bd",
     "grade": false,
     "grade_id": "cell-dd0d3f46b30801da",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def process_text(text, stem=False, remove_stopwords=False, lowercase_text=False):\n",
    "    \n",
    "    tokens = []\n",
    "    for token in tokenize(text):\n",
    "        if remove_stopwords and token.lower() in stopwords:\n",
    "            continue\n",
    "        if stem:\n",
    "            token = stem_token(token)\n",
    "        if lowercase_text:\n",
    "            token = token.lower()\n",
    "        tokens.append(token)\n",
    "\n",
    "    return tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:55.957508Z",
     "start_time": "2021-02-18T08:34:52.145655Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dbe4ca667be6842fdcf512fbcad50c7f",
     "grade": false,
     "grade_id": "cell-d427365ee0fb21d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# In this configuration:\n",
    "# Don't preprocess the text, except to tokenize \n",
    "config_1 = {\n",
    "  \"stem\": False,\n",
    "  \"remove_stopwords\" : False,\n",
    "  \"lowercase_text\": True\n",
    "} \n",
    "\n",
    "\n",
    "# In this configuration:\n",
    "# Preprocess the text, stem and remove stopwords\n",
    "config_2 = {\n",
    "  \"stem\": True,\n",
    "  \"remove_stopwords\" : True,\n",
    "  \"lowercase_text\": True, \n",
    "} \n",
    "doc_repr_1 = []\n",
    "doc_repr_2 = []\n",
    "for (doc_id, document) in docs:\n",
    "    doc_repr_1.append((doc_id, process_text(document, **config_1)))\n",
    "    doc_repr_2.append((doc_id, process_text(document, **config_2)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b60589aac19e80941d860d9b3f1e9a16",
     "grade": false,
     "grade_id": "cell-b1c102db61ae7495",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "--- \n",
    "\n",
    "## Section 2: Indexing\n",
    "\n",
    "[Back to Part 1](#part1)\n",
    "\n",
    "\n",
    "\n",
    "A retrieval function usually takes in a query document pair, and scores a query against a document.  Our document set is quite small - just a few thousand documents. However, consider a web-scale dataset with a few million documents. In such a scenario, it would become infeasible to score every query and document pair. We consider a simple inverted index, which maps a word to a set of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:55.973468Z",
     "start_time": "2021-02-18T08:34:55.959503Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c281c45196493b87e45e1b3fb4ddd6c9",
     "grade": false,
     "grade_id": "cell-077599b87e953209",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def build_tf_index(documents):\n",
    "    \"\"\"\n",
    "        Build an inverted index (with counts). The output is a dictionary which takes in a token\n",
    "        and returns a list of (doc_id, count) where 'count' is the count of the 'token' in 'doc_id'\n",
    "        Input: a list of documents - (doc_id, tokens) \n",
    "        Output: An inverted index. [token] -> [(doc_id, token_count)]\n",
    "    \"\"\"    \n",
    "    from collections import defaultdict\n",
    "    \n",
    "    index = defaultdict(str)\n",
    "\n",
    "    for (doc_id, tokens) in documents:\n",
    "        unique_tokens = set(tokens)\n",
    "        for word in unique_tokens:\n",
    "            count_word = int(tokens.count(word))\n",
    "            if word not in index.keys():\n",
    "                index[word] = [(doc_id, count_word)]\n",
    "            else:\n",
    "                index[word].append((doc_id, count_word))\n",
    "    \n",
    "    return index\n",
    "\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:56.721159Z",
     "start_time": "2021-02-18T08:34:55.975463Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e27540c1d8d77a3779a05f557f3f40c6",
     "grade": false,
     "grade_id": "cell-b2ff1676348b90a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create the 2 indices\n",
    "tf_index_1 = build_tf_index(doc_repr_1)\n",
    "tf_index_2 = build_tf_index(doc_repr_2)\n",
    "\n",
    "# This function returns the tf_index of the corresponding config\n",
    "def get_index(index_set):\n",
    "    assert index_set in {1, 2}\n",
    "    return {\n",
    "        1: tf_index_1,\n",
    "        2: tf_index_2\n",
    "    }[index_set]\n",
    "\n",
    "# This function preprocesses the text given the index set, according to the specified config\n",
    "def preprocess_query(text, index_set):\n",
    "    assert index_set in {1, 2}\n",
    "    if index_set == 1:\n",
    "        return process_text(text, **config_1)\n",
    "    elif index_set == 2:\n",
    "        return process_text(text, **config_2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "982112dca3f9a75e871bea74fe1adab4",
     "grade": false,
     "grade_id": "cell-89eba71f04310291",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "---\n",
    "## Section 3: Ranking \n",
    "\n",
    "[Back to Part 1](#part1)\n",
    "\n",
    "After cleaning and processing the dataset, the following IR systems are to considered which score documents against queries:\n",
    "- [Section 3.1: Bag of Words](#bow)\n",
    "- [Section 3.2: TF-IDF](#tfidf)\n",
    "- [Section 3.3: Query Likelihood Model](#qlm)\n",
    "- [Section 3.4: BM25](#bm25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "97c13d2e2cad60df4a70dcb61ea7c30e",
     "grade": false,
     "grade_id": "cell-3daf70a60e393adf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "--- \n",
    "\n",
    "### Section 3.1: Bag of Words <a class=\"anchor\" id=\"bow\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:56.782994Z",
     "start_time": "2021-02-18T08:34:56.760054Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1178c8a8908b0e4dc07add7aa49b7fde",
     "grade": false,
     "grade_id": "cell-de9cf0459c4b9324",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement this! (10 points)\n",
    "def bow_search(query, index_set):\n",
    "    \"\"\"\n",
    "        Perform a search over all documents with the given query. \n",
    "        Note: You have to use the `get_index` function created in the previous cells\n",
    "        Input: \n",
    "            query - a (unprocessed) query\n",
    "            index_set - the index to use\n",
    "        Output: a list of (document_id, score), sorted in descending relevance to the given query \n",
    "    \"\"\"\n",
    "    index = get_index(index_set)\n",
    "    processed_query = preprocess_query(query, index_set)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    query_score = []\n",
    "    \n",
    "    for query_word in processed_query:\n",
    "        for key, value in index.items():\n",
    "            if query_word == key:\n",
    "                bow_value = [(doc_id, 1) for doc_id, token_count in value]\n",
    "                query_score.extend(bow_value)\n",
    "    \n",
    "    dict_query = dict()\n",
    "    for (key, value) in query_score:\n",
    "        if key in dict_query:\n",
    "            dict_query[key] += value\n",
    "        else:\n",
    "            dict_query[key] = value\n",
    "\n",
    "    query_score = [(k, float(v)) for k, v in dict_query.items()]\n",
    "    query_score.sort(key=lambda x:x[1], reverse=True)\n",
    "    \n",
    "    return query_score\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:56.798949Z",
     "start_time": "2021-02-18T08:34:56.785985Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "644d6d33cf5075c6d9878d4fe24c6213",
     "grade": true,
     "grade_id": "cell-9f6aceae6dd9125f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW Results:\n",
      "Rank 0(1.0): Preliminary Report-International Algebraic Languag...\n",
      "Rank 1(1.0): ALGOL Sub-Committee Report - Extensions...\n",
      "Rank 2(1.0): The Use of Computers in Engineering Classroom Inst...\n",
      "Rank 3(1.0): Report on a Conference of University Computing Cen...\n",
      "Rank 4(1.0): Report on the Algorithmic Language ALGOL 60...\n"
     ]
    }
   ],
   "source": [
    "docs_by_id = dict(docs)\n",
    "def print_results(docs, len_limit=50):    \n",
    "    for i, (doc_id, score) in enumerate(docs):\n",
    "        doc_content = docs_by_id[doc_id].strip().replace(\"\\n\", \"\\\\n\")[:len_limit] + \"...\"\n",
    "        print(f\"Rank {i}({score:.2}): {doc_content}\")\n",
    "\n",
    "test_bow = bow_search(\"report\", index_set=1)[:5]\n",
    "print(f\"BOW Results:\")\n",
    "print_results(test_bow)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a5c2318004c5ce534b67c7a36bbc7c31",
     "grade": false,
     "grade_id": "cell-a5c09c79ac1f2871",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "### Section 3.2: TF-IDF <a class=\"anchor\" id=\"tfidf\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:56.862781Z",
     "start_time": "2021-02-18T08:34:56.848817Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11cdde77378ded394d7922fe36bbc5d1",
     "grade": false,
     "grade_id": "cell-9a2369f32e864b8a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_df(documents):\n",
    "    \"\"\"\n",
    "        Compute the document frequency of all terms in the vocabulary\n",
    "        Input: A list of documents\n",
    "        Output: A dictionary with {token: document frequency)\n",
    "    \"\"\"\n",
    "    \n",
    "    doc_freq = {}\n",
    "    \n",
    "    for doc in documents:\n",
    "        for word in set(doc):\n",
    "            if word not in doc_freq.keys():\n",
    "                doc_freq[word] = 1\n",
    "            else:\n",
    "                doc_freq[word] += 1\n",
    "                \n",
    "    return doc_freq\n",
    "    \n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:56.987447Z",
     "start_time": "2021-02-18T08:34:56.863777Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "154985511d7925c5793a1f97dea81880",
     "grade": false,
     "grade_id": "cell-4c3bddd0b73ac90e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# get the document frequencies of each document\n",
    "df_1 = compute_df([d[1] for d in doc_repr_1])\n",
    "df_2 = compute_df([d[1] for d in doc_repr_2])\n",
    "\n",
    "def get_df(index_set):\n",
    "    assert index_set in {1, 2}\n",
    "    return {\n",
    "        1: df_1,\n",
    "        2: df_2\n",
    "    }[index_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:57.018364Z",
     "start_time": "2021-02-18T08:34:57.004402Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b33c859693d1b383bcb53acea340027f",
     "grade": false,
     "grade_id": "cell-2fb5ba34b2994cd9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def tfidf_search(query, index_set):\n",
    "    \"\"\"\n",
    "        Perform a search over all documents with the given query using tf-idf. \n",
    "        Input: \n",
    "            query - a (unprocessed) query\n",
    "            index_set - the index to use\n",
    "        Output: a list of (document_id, score), sorted in descending relevance to the given query \n",
    "    \"\"\"\n",
    "    index = get_index(index_set)\n",
    "    df = get_df(index_set)\n",
    "    processed_query = preprocess_query(query, index_set)\n",
    "        \n",
    "    total_docs = len(docs)\n",
    "    idf = {key: np.log(total_docs / value) for (key, value) in df.items()}\n",
    "\n",
    "    query_score = []\n",
    "    \n",
    "    for query_word in processed_query:\n",
    "        for key, value in index.items():\n",
    "            if query_word == key:\n",
    "                tfidf_value = [(doc_id, token_count * idf[key]) for doc_id, token_count in value]\n",
    "                query_score.extend(tfidf_value)\n",
    "    \n",
    "    dict_query = dict()\n",
    "    for (key, value) in query_score:\n",
    "        if key in dict_query:\n",
    "            dict_query[key] += value\n",
    "        else:\n",
    "            dict_query[key] = value\n",
    "            \n",
    "    query_score = [(k, float(v)) for k, v in dict_query.items()]\n",
    "    query_score.sort(key=lambda x:x[1], reverse=True)\n",
    "    \n",
    "    return query_score\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:57.050280Z",
     "start_time": "2021-02-18T08:34:57.020358Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10b9fd39f3c9a9f3ca274c020ad79323",
     "grade": true,
     "grade_id": "cell-bc68aeeacf42beb3",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF Results:\n",
      "Rank 0(2.3e+01): An Information Algebra - Phase I Report-Language\\n...\n",
      "Rank 1(2.3e+01): Rejuvenating Experimental Computer Science\\nThis r...\n",
      "Rank 2(1.2e+01): ALGOL 60 Confidential\\nThe ALGOL 60 Report,* when ...\n",
      "Rank 3(7.8): Automatic Abstracting and Indexing Survey and Reco...\n",
      "Rank 4(7.8): A String Language for Symbol Manipulation Based on...\n"
     ]
    }
   ],
   "source": [
    "test_tfidf = tfidf_search(\"report\", index_set=1)[:5]\n",
    "print(f\"TFIDF Results:\")\n",
    "print_results(test_tfidf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cdffc83f0eaea937cf64a212e7e9af8d",
     "grade": false,
     "grade_id": "cell-f5d923459ba21733",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "--- \n",
    "\n",
    "### Section 3.3: Query Likelihood Model <a class=\"anchor\" id=\"qlm\"></a>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d739dc91a22bd48897f603885f95a74",
     "grade": false,
     "grade_id": "cell-5414dfd69dab8b94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Implement a QL model with Jelinek-Mercer Smoothing. That means an interpolated score is computed per word. In addition, it accumulates the scores by summing the **log** (smoothed) probability which leads to better numerical stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:57.239776Z",
     "start_time": "2021-02-18T08:34:57.226806Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8c6abf937ad333e628f1db891f2e29e",
     "grade": false,
     "grade_id": "cell-bb1f506409771257",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ql_search(query, index_set):\n",
    "    \"\"\"\n",
    "        Perform a search over all documents with the given query using a QL model \n",
    "        with Jelinek-Mercer Smoothing (set smoothing=0.1). \n",
    "        Input: \n",
    "            query - a (unprocessed) query\n",
    "            index_set - the index to use\n",
    "        Output: a list of (document_id, score), sorted in descending relevance to the given query \n",
    "    \"\"\"\n",
    "    index = get_index(index_set)\n",
    "    doc_lengths = get_doc_lengths(index_set)\n",
    "    processed_query = preprocess_query(query, index_set)\n",
    "        \n",
    "    sm = 0.1\n",
    "    rsm = 1 - 0.1\n",
    "    \n",
    "    coll_freq = {k: sum(count for doc_id, count in value) for k, value in index.items()}\n",
    "    coll_length = sum(doc_lengths.values()) \n",
    "    \n",
    "    query_score = []\n",
    "    \n",
    "    for query_word in processed_query:\n",
    "        for key, value in index.items():\n",
    "            if query_word == key:\n",
    "                ql_value = [(doc_id,\n",
    "                             np.log(rsm*(tkn_ct/doc_lengths[doc_id]) + sm*(coll_freq[key]/coll_length))) for doc_id, tkn_ct in value]\n",
    "                query_score.extend(ql_value)\n",
    "                \n",
    "                doc_contains = [doc_id for doc_id, token_count in value]\n",
    "                for i in range(len(docs)):\n",
    "                    i += 1\n",
    "                    if i not in doc_contains:\n",
    "                        query_score.append((i, np.log(0 + sm*(coll_freq[key]/coll_length))))\n",
    "    \n",
    "    dict_query = dict()\n",
    "    for (key, value) in query_score:\n",
    "        if key in dict_query:\n",
    "            dict_query[key] += value\n",
    "        else:\n",
    "            dict_query[key] = value\n",
    "\n",
    "    query_score = [(k, float(v)) for k, v in dict_query.items()]\n",
    "    query_score.sort(key=lambda x:x[1], reverse=True)\n",
    "    \n",
    "    return query_score\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:57.479130Z",
     "start_time": "2021-02-18T08:34:57.241768Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b12a7f3355193a257fd9f5f69a66562",
     "grade": true,
     "grade_id": "cell-850e9d6369bcec32",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0(-1.7): A Report Writer For COBOL...\n",
      "Rank 1(-1.7): A CRT Report Generating System...\n",
      "Rank 2(-1.9): Preliminary Report-International Algebraic Languag...\n",
      "Rank 3(-1.9): Supplement to the ALGOL 60 Report...\n",
      "Rank 4(-2.1): ALGOL Sub-Committee Report - Extensions...\n",
      "\n",
      "Rank 0(-1.7e+01): A Report Writer For COBOL...\n",
      "Rank 1(-1.7e+01): A CRT Report Generating System...\n",
      "Rank 2(-1.9e+01): Preliminary Report-International Algebraic Languag...\n",
      "Rank 3(-1.9e+01): Supplement to the ALGOL 60 Report...\n",
      "Rank 4(-2.1e+01): ALGOL Sub-Committee Report - Extensions...\n"
     ]
    }
   ],
   "source": [
    "test_ql_results = ql_search(\"report\", index_set=1)[:5]\n",
    "print_results(test_ql_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c02f14705d679579b1aa9f78f54779d5",
     "grade": false,
     "grade_id": "cell-f44088bfdac1dc90",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Section 3.4: BM25 <a class=\"anchor\" id=\"bm25\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:57.558918Z",
     "start_time": "2021-02-18T08:34:57.544957Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e57efe06ea92af1c83784a42eb3d86e0",
     "grade": false,
     "grade_id": "cell-15640fc9b5d00a3c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def bm25_search(query, index_set):\n",
    "    \"\"\"\n",
    "        Perform a search over all documents with the given query using BM25. Use k_1 = 1.5 and b = 0.75\n",
    "        Input: \n",
    "            query - a (unprocessed) query\n",
    "            index_set - the index to use\n",
    "        Output: a list of (document_id, score), sorted in descending relevance to the given query \n",
    "    \"\"\"\n",
    "    \n",
    "    index = get_index(index_set)\n",
    "    df = get_df(index_set)\n",
    "    doc_lengths = get_doc_lengths(index_set)\n",
    "    processed_query = preprocess_query(query, index_set)\n",
    "        \n",
    "    k1 = 1.5\n",
    "    b = 0.75\n",
    "    k2 = k1 + 1\n",
    "    b2 = 1 - b\n",
    "    \n",
    "    total_docs = len(docs)\n",
    "    avg_dl = np.mean(list(doc_lengths.values()))\n",
    "    idf = {key: np.log(total_docs / value) for (key, value) in df.items()}\n",
    "\n",
    "    query_score = []\n",
    "    \n",
    "    for query_word in processed_query:\n",
    "        for key, value in index.items():\n",
    "            if query_word == key:\n",
    "                bm_value = [(doc_id, idf[key] * ((k2*tkn_ct)/(k1*(b2+(b*doc_lengths[doc_id]/avg_dl))+tkn_ct))) for doc_id, tkn_ct in value]\n",
    "                query_score.extend(bm_value)\n",
    "    \n",
    "    dict_query = dict()\n",
    "    for (key, value) in query_score:\n",
    "        if key in dict_query:\n",
    "            dict_query[key] += value\n",
    "        else:\n",
    "            dict_query[key] = value\n",
    "            \n",
    "    query_score = [(k, float(v)) for k, v in dict_query.items()]\n",
    "    query_score.sort(key=lambda x:x[1], reverse=True)\n",
    "    \n",
    "    return query_score\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:57.589836Z",
     "start_time": "2021-02-18T08:34:57.560913Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4be9de5d4e94637960d83725422bea6c",
     "grade": true,
     "grade_id": "cell-d10536bca72c74b1",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0(6.7): A Report Writer For COBOL...\n",
      "Rank 1(6.7): A CRT Report Generating System...\n",
      "Rank 2(6.6): Preliminary Report-International Algebraic Languag...\n",
      "Rank 3(6.6): Supplement to the ALGOL 60 Report...\n",
      "Rank 4(6.5): ALGOL Sub-Committee Report - Extensions...\n"
     ]
    }
   ],
   "source": [
    "test_bm25_results = bm25_search(\"report\", index_set=1)[:5]\n",
    "print_results(test_bm25_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:57.668652Z",
     "start_time": "2021-02-18T08:34:57.654662Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dfeb204b390acc0794dbdcac92b0cf2c",
     "grade": false,
     "grade_id": "cell-c9c2bb76354e8d97",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# class for results\n",
    "ResultRow = namedtuple(\"ResultRow\", [\"doc_id\", \"snippet\", \"score\"])\n",
    "# doc_id -> doc\n",
    "docs_by_id = dict((d[0], d[1]) for d in docs)\n",
    "\n",
    "def highlight_text(document, query, tol=17):\n",
    "    import re\n",
    "    tokens = tokenize(query)\n",
    "    regex = \"|\".join(f\"(\\\\b{t}\\\\b)\" for t in tokens)\n",
    "    regex = re.compile(regex, flags=re.IGNORECASE)\n",
    "    output = \"\"\n",
    "    i = 0\n",
    "    for m in regex.finditer(document):\n",
    "        start_idx = max(0, m.start() - tol)\n",
    "        end_idx = min(len(document), m.end() + tol)\n",
    "        output += \"\".join([\"...\",\n",
    "                        document[start_idx:m.start()],\n",
    "                        \"<strong>\",\n",
    "                        document[m.start():m.end()],\n",
    "                        \"</strong>\",\n",
    "                        document[m.end():end_idx],\n",
    "                        \"...\"])\n",
    "    return output.replace(\"\\n\", \" \")\n",
    "\n",
    "\n",
    "def make_results(query, search_fn, index_set):\n",
    "    results = []\n",
    "    for doc_id, score in search_fn(query, index_set):\n",
    "        highlight = highlight_text(docs_by_id[doc_id], query)\n",
    "        if len(highlight.strip()) == 0:\n",
    "            highlight = docs_by_id[doc_id]\n",
    "        results.append(ResultRow(doc_id, highlight, score))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:57.700572Z",
     "start_time": "2021-02-18T08:34:57.669624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ee5caf2f7b4495ad742e27316b8d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Search Bar')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search_fn = bm25_search\n",
    "index_set = 1\n",
    "\n",
    "text = widgets.Text(description=\"Search Bar\", width=200)\n",
    "display(text)\n",
    "\n",
    "def handle_submit(sender):\n",
    "    print(f\"Searching for: '{sender.value}'\")\n",
    "    \n",
    "    results = make_results(sender.value, search_fn, index_set)\n",
    "    \n",
    "    # display only the top 5\n",
    "    results = results[:5]\n",
    "    \n",
    "    body = \"\"\n",
    "    for idx, r in enumerate(results):\n",
    "        body += f\"<li>Document #{r.doc_id}({r.score}): {r.snippet}</li>\"\n",
    "    display(HTML(f\"<ul>{body}</ul>\"))\n",
    "    \n",
    "\n",
    "text.on_submit(handle_submit)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b315c280048a50e8bad7d6250f6f39d1",
     "grade": false,
     "grade_id": "cell-8d46fe8e4f3d8cdb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Section 4: Evaluation <a class=\"anchor\" id=\"evaluation\"></a>\n",
    "\n",
    "[Back to Part 1](#part1)\n",
    "\n",
    "Use offline evaluation metrics to understand the performs of the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:57.780327Z",
     "start_time": "2021-02-18T08:34:57.767396Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef347565a0990ddbd049835105753d59",
     "grade": false,
     "grade_id": "cell-ee5253a4ef602fce",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def read_qrels(root_folder = \"./datasets/\"):   \n",
    "    file_location = os.path.join(root_folder, \"qrels.text\")\n",
    "\n",
    "    relevant_docs = {}\n",
    "    \n",
    "    with open(file_location, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    qrels = []\n",
    "    \n",
    "    for line in lines:\n",
    "        items_line = line.split(' ')\n",
    "        qrels.append((int(items_line[0].lstrip('0')), int(items_line[1].lstrip('0'))))\n",
    "        \n",
    "    for x, y in qrels:\n",
    "        relevant_docs.setdefault(x, []).append(y)\n",
    "    \n",
    "    return relevant_docs\n",
    "    \n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:57.812268Z",
     "start_time": "2021-02-18T08:34:57.798279Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad3cc3234a361d269ecb6b59cc447e9f",
     "grade": false,
     "grade_id": "cell-494bd0cce108ed67",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def precision_k(results, relevant_docs, k):   \n",
    "    return np.sum([1 for y in [x[0] for x in results[:k]] if y in relevant_docs])/k\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:57.860111Z",
     "start_time": "2021-02-18T08:34:57.814264Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "964b214dbfff8fc53cada864019ee863",
     "grade": true,
     "grade_id": "cell-e7ff0d91c319ca64",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: What articles exist which deal with TSS (Time Sharing System), an\n",
      "operating system for IBM computers?\n",
      "precision@10 = 0.2\n"
     ]
    }
   ],
   "source": [
    "qid = queries[0][0]\n",
    "qtext = queries[0][1]\n",
    "print(f'query:{qtext}')\n",
    "results = bm25_search(qtext, 2)\n",
    "precision = precision_k(results, qrels[qid], 10)\n",
    "print(f'precision@10 = {precision}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:57.876103Z",
     "start_time": "2021-02-18T08:34:57.862106Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b2020e5741ae03b3fe35817ed8f4ccaa",
     "grade": false,
     "grade_id": "cell-c323fc8c3f8a7cf8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def recall_k(results, relevant_docs, k):\n",
    "   \n",
    "    to_return = np.sum([1 for y in [x[0] for x in  results[:k]] if y in relevant_docs])/len(relevant_docs)\n",
    "    \n",
    "    return to_return\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:57.907984Z",
     "start_time": "2021-02-18T08:34:57.877067Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56b6e0b8522f8b2dffbfb3206b2efa84",
     "grade": true,
     "grade_id": "cell-b25172161aef165c",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: SETL, Very High Level Languages\n",
      "recall@10 = 0.3157894736842105\n"
     ]
    }
   ],
   "source": [
    "qid = queries[10][0]\n",
    "qtext = queries[10][1]\n",
    "print(f'query:{qtext}')\n",
    "results = bm25_search(qtext, 2)\n",
    "recall = recall_k(results, qrels[qid], 10)\n",
    "print(f'recall@10 = {recall}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:57.923974Z",
     "start_time": "2021-02-18T08:34:57.910976Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aae2c62f2ffd76f5b6c004e9519b9f14",
     "grade": false,
     "grade_id": "cell-e50925fa9093a30d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def average_precision(results, relevant_docs):  \n",
    "    position_k={}\n",
    "    \n",
    "    for i in range(1,len(results)+1,1):\n",
    "        position_k[i]=precision_k(results, relevant_docs, i)\n",
    "        \n",
    "    index=[]\n",
    "    for i,j in enumerate(results):\n",
    "         if j[0] in relevant_docs:\n",
    "            index.append(i+1)\n",
    "            \n",
    "    if len(index)>0:\n",
    "        return sum([position_k[x] for x in index])/len(index)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:59.270047Z",
     "start_time": "2021-02-18T08:34:57.925936Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5db8cb2dfd3a77554f4147b409f47f38",
     "grade": true,
     "grade_id": "cell-8a1f7ec98571e58b",
     "locked": true,
     "points": 12,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: computational complexity, intractability, class-complete reductions,\n",
      "algorithms and efficiency\n",
      "MAP = 0.17269233631989397\n"
     ]
    }
   ],
   "source": [
    "qid = queries[20][0]\n",
    "qtext = queries[20][1]\n",
    "print(f'query:{qtext}')\n",
    "results = bm25_search(qtext, 2)\n",
    "mean_ap = average_precision(results, qrels[qid])\n",
    "print(f'MAP = {mean_ap}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:59.285005Z",
     "start_time": "2021-02-18T08:34:59.273040Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ac94db728e23ea1f5dc0d509473c6fb",
     "grade": false,
     "grade_id": "cell-64262889f9b267ea",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def err(results, relevant_docs):  \n",
    "    max_grade = 1.0\n",
    "    step_down = 1.0\n",
    "    error = 0.0\n",
    "\n",
    "    for i, (doc_id, score) in enumerate(results):\n",
    "        grade = 1. if doc_id in relevant_docs else 0.\n",
    "        t = (pow(2, grade) - 1) / pow(2, max_grade)\n",
    "        error += step_down * (t / (i + 1.))\n",
    "        step_down *= (1. - t)\n",
    "        \n",
    "    return error\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:34:59.395709Z",
     "start_time": "2021-02-18T08:34:59.287028Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb97e6d89a0b992b642e4e0ff36ff9f5",
     "grade": true,
     "grade_id": "cell-071e3970ff1afae4",
     "locked": true,
     "points": 12,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: I'd like to find articles describing the use of singular value decomposition\n",
      "in digital image processing.  Applications include finding approximations\n",
      "to the original image and restoring images that are subject to noise. An\n",
      "article on the subject is H.C. Andrews and C.L. Patterson \"Outer product\n",
      "expansions and their uses in digital image processing\", American Mathematical\n",
      "Monthly, vol. 82.\n",
      "ERR = 0.625\n"
     ]
    }
   ],
   "source": [
    "qid = queries[30][0]\n",
    "qtext = queries[30][1]\n",
    "print(f'query:{qtext}')\n",
    "results = bm25_search(qtext, 2)\n",
    "ERR = err(results, qrels[qid])\n",
    "print(f'ERR = {ERR}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b3eb77be74eecca205fc7b47316d1627",
     "grade": false,
     "grade_id": "cell-bb60dd5c092d0f2e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "# Part 2: Semantic-based Matching <a class=\"anchor\" id=\"part2\"></a>\n",
    "\n",
    "[Back to top](#top)\n",
    "\n",
    "We will now experiment with methods that go beyond lexical methods like TF-IDF, which operate at the word level and are high dimensional and sparse, and look at methods which constructs low dimensional dense representations of queries and documents. \n",
    "\n",
    "Since these low-dimensional methods have a higher time complexity, they are typically used in conjunction with methods like BM-25. That is, instead of searching through potentially million documents to find matches using low dimensional vectors, a list of K documents are retrieved using BM25, and then **re-ranked** using the other method. \n",
    "\n",
    "LSI/LDA takes documents that are similar on a semantic level - for instance, if they are describing the same topic - and projects them into nearby vectors, despite having low lexical overlap.\n",
    "Table of contents:\n",
    "- [Section 6: LSI](#lsi) \n",
    "- [Section 7: LDA](#lda) \n",
    "- [Section 8: Word2Vec/Doc2Vec](#2vec) \n",
    "- [Section 8: Re-ranking](#reranking) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f7c7b2cab82f576ed0acf836ca57171c",
     "grade": false,
     "grade_id": "cell-6b2c81e7a8abd180",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "## Section 6: Latent Semantic Indexing (LSI) <a class=\"anchor\" id=\"lsi\"></a>\n",
    "\n",
    "[Back to Part 2](#part2)\n",
    "\n",
    "LSI is one of the methods to embed the queries and documents into vectors. It is based on a method similar to Principal Component Analysis (PCA) for obtaining a dense concept matrix out of the sparse term-document matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:45:20.191733Z",
     "start_time": "2021-02-18T08:45:19.971113Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c17ee75319cb517e2bf48ec3d9efc329",
     "grade": false,
     "grade_id": "cell-59913daee47f680d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel, LsiModel, Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim import downloader as g_downloader\n",
    "# gensim uses logging, so set it up \n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:45:20.223646Z",
     "start_time": "2021-02-18T08:45:20.209685Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06a712ee75fc213a21c5f0067fd8fe28",
     "grade": false,
     "grade_id": "cell-0e8189f5f93de33f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def dot(vec_1,vec_2): \n",
    "    vec_1 = list(list(zip(*vec_1))[1])\n",
    "    vec_2 = list(list(zip(*vec_2))[1])\n",
    "    dot_product = np.dot(vec_1,vec_2)\n",
    "    return dot_product\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "def cosine_sim(vec_1, vec_2):\n",
    "    \n",
    "    cosine = dot(vec_1,vec_2)/(np.sqrt(dot(vec_1,vec_1))*np.sqrt(dot(vec_2,vec_2)))\n",
    "    if np.isnan(cosine):\n",
    "        return 0.0\n",
    "    else:\n",
    "        return cosine\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:45:20.271519Z",
     "start_time": "2021-02-18T08:45:20.257557Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ecc111d58182570e2252b8ef5d6b02af",
     "grade": false,
     "grade_id": "cell-937936cea18711ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class VectorSpaceRetrievalModel:\n",
    "    \"\"\"\n",
    "        Parent class for Dense Vector Retrieval models\n",
    "    \"\"\"\n",
    "    def __init__(self, doc_repr):\n",
    "        \"\"\"\n",
    "            document_collection: \n",
    "                [\n",
    "                    (doc_id_1, [token 1, token 2, ...]), \n",
    "                    (doc_id_2, [token 1, token 2, ....]) \n",
    "                    ...\n",
    "                ]\n",
    "\n",
    "        \"\"\"\n",
    "        self.doc_repr = doc_repr\n",
    "        self.documents = [_[1] for _ in self.doc_repr]\n",
    "        \n",
    "        # construct a dictionary\n",
    "        self.dictionary = Dictionary(self.documents)\n",
    "        # Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "        self.dictionary.filter_extremes(no_below=10)\n",
    "        self.corpus = [self.dictionary.doc2bow(doc) for doc in self.documents]\n",
    "    \n",
    "        # Make a index to word dictionary.\n",
    "        temp = self.dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "        self.id2word = self.dictionary.id2token\n",
    "        \n",
    "        # this is set by the train_model function\n",
    "        self.model = None\n",
    "        \n",
    "        \n",
    "    def vectorize_documents(self):\n",
    "        \"\"\"\n",
    "            Returns a doc_id -> vector dictionary\n",
    "        \"\"\"\n",
    "        vectors = {}\n",
    "        for (doc_id, _), cc in zip(self.doc_repr, self.corpus):\n",
    "            vectors[doc_id] = self.model[cc]\n",
    "        return vectors\n",
    "\n",
    "    def vectorize_query(self, query):\n",
    "        query = process_text(query, **config_2)\n",
    "        query_vector = self.dictionary.doc2bow(query)\n",
    "        return self.model[query_vector]\n",
    "    \n",
    "    def train_model(self):\n",
    "        \"\"\"\n",
    "            Trains a model and sets the 'self.model' variable. \n",
    "            Make sure to use the variables created in the __init__ method.\n",
    "            e.g the variables which may be useful: {corpus, dictionary, id2word}\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:45:20.286478Z",
     "start_time": "2021-02-18T08:45:20.273513Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e90eedc27c248bc1ae050518a46a46c",
     "grade": false,
     "grade_id": "cell-307682c9089f15d6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class LsiRetrievalModel(VectorSpaceRetrievalModel):\n",
    "    def __init__(self, doc_repr):\n",
    "        super().__init__(doc_repr)\n",
    "        \n",
    "        self.num_topics = 100\n",
    "        self.chunksize = 2000\n",
    "    \n",
    "    def train_model(self):        \n",
    "        model = LsiModel(corpus=self.corpus, id2word=self.id2word, num_topics=self.num_topics, chunksize=self.chunksize)\n",
    "        self.model = model\n",
    "        return model\n",
    "    \n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:45:20.915757Z",
     "start_time": "2021-02-18T08:45:20.901794Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a8389d2f0635c3405e2b0b27ed9f327",
     "grade": false,
     "grade_id": "cell-250515d288e80cdc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class DenseRetrievalRanker:\n",
    "    def __init__(self, vsrm, similarity_fn):\n",
    "        \"\"\"\n",
    "            vsrm: instance of `VectorSpaceRetrievalModel`\n",
    "            similarity_fn: function instance that takes in two vectors \n",
    "                            and returns a similarity score e.g cosine_sim defined earlier\n",
    "        \"\"\"\n",
    "        self.vsrm = vsrm \n",
    "        self.vectorized_documents = self.vsrm.vectorize_documents()\n",
    "        self.similarity_fn = similarity_fn\n",
    "    \n",
    "    def _compute_sim(self, query_vector):\n",
    "        \"\"\"\n",
    "            Compute the similarity of `query_vector` to documents in \n",
    "            `self.vectorized_documents` using `self.similarity_fn`\n",
    "            Returns a list of (doc_id, score) tuples\n",
    "        \"\"\"        \n",
    "        #list_scores = [(doc_id, self.similarity_fn(query_vector, vec)) for doc_id, vec in self.vectorized_documents.items()]\n",
    "        list_scores = list()\n",
    "        if not query_vector:\n",
    "            return []\n",
    "        for doc_id, vec in self.vectorized_documents.items():\n",
    "            if not vec: #doc_id in [235, 913, 917, 2782]: I think we should do \"if not vec:\" instead\n",
    "                score = 0\n",
    "            else:\n",
    "                score = self.similarity_fn(query_vector, vec)\n",
    "            list_scores.append((doc_id, score))\n",
    "            \n",
    "        return list_scores\n",
    "    \n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    \n",
    "    def search(self, query):\n",
    "        scores = self._compute_sim(self.vsrm.vectorize_query(query))\n",
    "        scores.sort(key=lambda _:-_[1])\n",
    "        return scores  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:45:21.951512Z",
     "start_time": "2021-02-18T08:45:20.918754Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f237dd1ef6c1783c06797f4b514421f5",
     "grade": true,
     "grade_id": "cell-b73068b3e77a8e31",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(599, 0.7996616893459932),\n",
       " (947, 0.5727198744397531),\n",
       " (53, 0.5036188582993223),\n",
       " (1339, 0.4618035237113527),\n",
       " (3160, 0.44068710472917144)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Function check\n",
    "lsi = LsiRetrievalModel(doc_repr_2)\n",
    "lsi.train_model()\n",
    "drm_lsi = DenseRetrievalRanker(lsi, cosine_sim)\n",
    "drm_lsi.search(\"report\")[:5]\n",
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:45:21.978469Z",
     "start_time": "2021-02-18T08:45:21.952510Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11734bc7674377b340ad51297a8e8bb5",
     "grade": false,
     "grade_id": "cell-efd1d08dfc04ec3e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4468a28a6ae446cb91e7d2f76b9bc5f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Search Bar')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search_fn = drm_lsi.search\n",
    "\n",
    "text = widgets.Text(description=\"Search Bar\", width=200)\n",
    "display(text)\n",
    "\n",
    "def make_results_2(query, search_fn):\n",
    "    results = []\n",
    "    for doc_id, score in search_fn(query):\n",
    "        highlight = highlight_text(docs_by_id[doc_id], query)\n",
    "        if len(highlight.strip()) == 0:\n",
    "            highlight = docs_by_id[doc_id]\n",
    "        results.append(ResultRow(doc_id, highlight, score))\n",
    "    return results\n",
    "\n",
    "def handle_submit_2(sender):\n",
    "    print(f\"Searching for: '{sender.value}' (SEARCH FN: {search_fn})\")\n",
    "    \n",
    "    results = make_results_2(sender.value, search_fn)\n",
    "    \n",
    "    # display only the top 5\n",
    "    results = results[:5]\n",
    "    \n",
    "    body = \"\"\n",
    "    for idx, r in enumerate(results):\n",
    "        body += f\"<li>Document #{r.doc_id}({r.score}): {r.snippet}</li>\"\n",
    "    display(HTML(f\"<ul>{body}</ul>\"))\n",
    "    \n",
    "\n",
    "text.on_submit(handle_submit_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d074ce1ca48384cdda78742741c938be",
     "grade": false,
     "grade_id": "cell-3a86cef264d8f6cf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "## Section 7: Latent Dirichlet Allocation (LDA) <a class=\"anchor\" id=\"lda\"></a>\n",
    "\n",
    "[Back to Part 2](#part2)\n",
    "\n",
    "LDA, unlike LSI, outputs a topic **distribution**, not a vector. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "db01092373b18f0c9dfed1bb17db4ad9",
     "grade": false,
     "grade_id": "cell-6b78ad22c2d60ba7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "The Jenson-Shannon divergence is a symmetric and finite measure on two probability distributions (unlike the KL, which is neither). For identical distributions, the JSD is equal to 0, and since our code uses 0 as irrelevant and higher scores as relevant, we use `(1 - JSD)` as the score or 'similarity' in our setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:45:21.994397Z",
     "start_time": "2021-02-18T08:45:21.979437Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a579e6cd7a24a3516bc9a84528b392d3",
     "grade": false,
     "grade_id": "cell-d2376a85a4841e98",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def jenson_shannon_divergence(vec_1, vec_2, assert_prob=False):\n",
    "    \n",
    "    if assert_prob:\n",
    "        assert sum([v for k,v in vec_1]) == 1\n",
    "        assert sum([v for k,v in vec_2]) == 1\n",
    "        assert min([v for k,v in vec_1]) > 0\n",
    "        assert min([v for k,v in vec_2]) > 0\n",
    "    vec_1 = list(list(zip(*vec_1))[1])\n",
    "    vec_2 = list(list(zip(*vec_2))[1])\n",
    "    mean = list(0.5*(np.array(vec_1) + np.array(vec_2)))\n",
    "    kl_divergence_1 = sum(vec_1[i]*np.log2(vec_1[i]/mean[i]) for i in range(len(vec_1)))\n",
    "    kl_divergence_2 = sum(vec_2[i]*np.log2(vec_2[i]/mean[i]) for i in range(len(vec_2)))\n",
    "    \n",
    "    return 0.5*kl_divergence_1 + 0.5*kl_divergence_2\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "\n",
    "def jenson_shannon_sim(vec_1, vec_2, assert_prob=False):\n",
    "    return 1 - jenson_shannon_divergence(vec_1, vec_2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:45:22.025291Z",
     "start_time": "2021-02-18T08:45:22.010354Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27de8e4fa85536bb396b73bfc51b3f50",
     "grade": false,
     "grade_id": "cell-021a48dff4a8bb91",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class LdaRetrievalModel(VectorSpaceRetrievalModel):\n",
    "    def __init__(self, doc_repr):\n",
    "        super().__init__(doc_repr)\n",
    "        \n",
    "        # use these parameters in the train_model method\n",
    "        self.num_topics = 100\n",
    "        self.chunksize = 2000\n",
    "        self.passes = 20\n",
    "        self.iterations = 400\n",
    "        self.eval_every = 10\n",
    "        # this is need to get full vectors\n",
    "        self.minimum_probability=0.0\n",
    "        self.alpha='auto'\n",
    "        self.eta='auto'\n",
    "    \n",
    "    \n",
    "    def train_model(self):\n",
    "        \n",
    "        model = LdaModel(corpus=self.corpus, id2word=self.id2word, num_topics=self.num_topics, chunksize=self.chunksize,\\\n",
    "                        passes=self.passes, alpha=self.alpha,eval_every=self.eval_every, minimum_probability=self.minimum_probability,\\\n",
    "                        eta=self.eta, iterations=self.iterations)\n",
    "        self.model = model\n",
    "        return model\n",
    "    \n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:46:14.565672Z",
     "start_time": "2021-02-18T08:46:12.756514Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1eed05aebc41de8f8eaa505fe939db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Search Bar')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lda = LdaRetrievalModel(doc_repr_2)\n",
    "lda.train_model()\n",
    "drm_lda = DenseRetrievalRanker(lda, jenson_shannon_sim)\n",
    "\n",
    "search_fn = drm_lda.search\n",
    "\n",
    "text = widgets.Text(description=\"Search Bar\", width=200)\n",
    "display(text)\n",
    "\n",
    "\n",
    "text.on_submit(handle_submit_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d7f15863b655119b45f4d89354e5661",
     "grade": false,
     "grade_id": "cell-190cd0854b2791cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Section 8: Word2Vec/Doc2Vec <a class=\"anchor\" id=\"2vec\"></a>\n",
    "\n",
    "[Back to Part 2](#part2)\n",
    "\n",
    "Word2Vec creates representations of words, not documents, so the word level vectors need to be aggregated to obtain a representation for the document. Here, we will simply take the mean of the vectors. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:46:16.328218Z",
     "start_time": "2021-02-18T08:46:14.566680Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83ab733608ed14c29c09b36b4e1b6daa",
     "grade": false,
     "grade_id": "cell-2b73759f9baf688f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-18 09:46:14,573 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2021-02-18 09:46:14,702 : INFO : built Dictionary(5937 unique tokens: ['-', 'algebra', 'intern', 'languag', 'preliminari']...) from 3204 documents (total 115978 corpus positions)\n",
      "2021-02-18 09:46:14,708 : INFO : discarding 4740 tokens: [('repeat', 8), ('glossari', 7), ('inspect', 8), ('uncol', 2), ('rung', 9), ('secant', 2), ('.', 1603), ('acceler', 6), ('diverg', 3), ('induc', 9)]...\n",
      "2021-02-18 09:46:14,709 : INFO : keeping 1197 tokens which were in no less than 10 and no more than 1602 (=50.0%) documents\n",
      "2021-02-18 09:46:14,712 : INFO : resulting dictionary: Dictionary(1197 unique tokens: ['-', 'algebra', 'intern', 'languag', 'preliminari']...)\n",
      "2021-02-18 09:46:14,775 : INFO : collecting all words and their counts\n",
      "2021-02-18 09:46:14,777 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-02-18 09:46:14,796 : INFO : collected 5937 word types from a corpus of 115978 raw words and 3204 sentences\n",
      "2021-02-18 09:46:14,797 : INFO : Loading a fresh vocabulary\n",
      "2021-02-18 09:46:14,807 : INFO : effective_min_count=1 retains 5937 unique words (100% of original 5937, drops 0)\n",
      "2021-02-18 09:46:14,808 : INFO : effective_min_count=1 leaves 115978 word corpus (100% of original 115978, drops 0)\n",
      "2021-02-18 09:46:14,824 : INFO : deleting the raw counts dictionary of 5937 items\n",
      "2021-02-18 09:46:14,825 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2021-02-18 09:46:14,826 : INFO : downsampling leaves estimated 92353 word corpus (79.6% of prior 115978)\n",
      "2021-02-18 09:46:14,840 : INFO : estimated required memory for 5937 words and 100 dimensions: 7718100 bytes\n",
      "2021-02-18 09:46:14,841 : INFO : resetting layer weights\n",
      "2021-02-18 09:46:15,909 : INFO : training model with 3 workers on 5937 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-02-18 09:46:15,981 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-18 09:46:15,982 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-18 09:46:15,984 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-18 09:46:15,985 : INFO : EPOCH - 1 : training on 115978 raw words (92382 effective words) took 0.1s, 1310489 effective words/s\n",
      "2021-02-18 09:46:16,047 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-18 09:46:16,052 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-18 09:46:16,056 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-18 09:46:16,057 : INFO : EPOCH - 2 : training on 115978 raw words (92434 effective words) took 0.1s, 1362754 effective words/s\n",
      "2021-02-18 09:46:16,121 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-18 09:46:16,129 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-18 09:46:16,132 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-18 09:46:16,133 : INFO : EPOCH - 3 : training on 115978 raw words (92491 effective words) took 0.1s, 1292350 effective words/s\n",
      "2021-02-18 09:46:16,205 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-18 09:46:16,207 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-18 09:46:16,210 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-18 09:46:16,211 : INFO : EPOCH - 4 : training on 115978 raw words (92441 effective words) took 0.1s, 1254742 effective words/s\n",
      "2021-02-18 09:46:16,289 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-18 09:46:16,294 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-18 09:46:16,296 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-18 09:46:16,298 : INFO : EPOCH - 5 : training on 115978 raw words (92306 effective words) took 0.1s, 1148035 effective words/s\n",
      "2021-02-18 09:46:16,299 : INFO : training on a 579890 raw words (462054 effective words) took 0.4s, 1195981 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 0.086458154),\n",
       " (1, 0.47689313),\n",
       " (2, -0.116774),\n",
       " (3, -1.0261179),\n",
       " (4, 0.40345186),\n",
       " (5, -0.08808004),\n",
       " (6, -0.32522276),\n",
       " (7, 0.023351425),\n",
       " (8, -0.26708075),\n",
       " (9, -0.019330628),\n",
       " (10, -0.29249766),\n",
       " (11, 0.04949044),\n",
       " (12, -0.07726371),\n",
       " (13, -1.0515071),\n",
       " (14, 0.092795976),\n",
       " (15, -0.49762914),\n",
       " (16, 0.36850604),\n",
       " (17, -0.20609863),\n",
       " (18, 0.58328485),\n",
       " (19, -0.22554697),\n",
       " (20, 0.43124232),\n",
       " (21, -0.20167613),\n",
       " (22, -0.074251674),\n",
       " (23, 0.17088152),\n",
       " (24, -0.14901637),\n",
       " (25, 1.1308036),\n",
       " (26, -0.41290075),\n",
       " (27, -0.10039292),\n",
       " (28, 0.4723352),\n",
       " (29, 0.6130844),\n",
       " (30, -0.26171646),\n",
       " (31, 0.07677623),\n",
       " (32, 0.3208393),\n",
       " (33, -0.3194513),\n",
       " (34, -0.27150375),\n",
       " (35, 0.31206724),\n",
       " (36, -0.77079135),\n",
       " (37, -0.7586395),\n",
       " (38, 0.228283),\n",
       " (39, 1.1315128),\n",
       " (40, 0.051851362),\n",
       " (41, 0.010796506),\n",
       " (42, 0.3717191),\n",
       " (43, -0.75109404),\n",
       " (44, 0.07001864),\n",
       " (45, -0.66212624),\n",
       " (46, 0.36532757),\n",
       " (47, -0.39243025),\n",
       " (48, 0.72810745),\n",
       " (49, -0.2040465),\n",
       " (50, 0.366937),\n",
       " (51, 0.07305568),\n",
       " (52, 0.07312008),\n",
       " (53, 0.40273568),\n",
       " (54, 0.58351684),\n",
       " (55, 0.01294411),\n",
       " (56, -0.23830988),\n",
       " (57, -0.06789668),\n",
       " (58, 0.57918566),\n",
       " (59, -0.6266365),\n",
       " (60, 0.4436687),\n",
       " (61, -0.5501367),\n",
       " (62, 0.24446015),\n",
       " (63, -0.26303372),\n",
       " (64, 0.53166306),\n",
       " (65, -0.3208225),\n",
       " (66, -0.34135088),\n",
       " (67, 0.20438664),\n",
       " (68, -0.48459077),\n",
       " (69, -0.25823805),\n",
       " (70, -0.40402132),\n",
       " (71, 0.3897769),\n",
       " (72, -0.45197812),\n",
       " (73, -0.6117323),\n",
       " (74, -0.075122304),\n",
       " (75, 0.61223274),\n",
       " (76, -0.11718115),\n",
       " (77, -0.1332483),\n",
       " (78, -0.028396873),\n",
       " (79, 0.04991695),\n",
       " (80, -0.4159489),\n",
       " (81, -0.13558318),\n",
       " (82, 0.66911864),\n",
       " (83, 0.43699244),\n",
       " (84, -0.3895292),\n",
       " (85, 0.062892705),\n",
       " (86, 0.18684046),\n",
       " (87, -0.9522201),\n",
       " (88, -0.3912237),\n",
       " (89, 0.13548383),\n",
       " (90, -0.30052817),\n",
       " (91, 0.094983146),\n",
       " (92, -0.053093407),\n",
       " (93, 0.44571495),\n",
       " (94, 0.2849528),\n",
       " (95, -0.101835474),\n",
       " (96, 0.23282112),\n",
       " (97, 0.5316269),\n",
       " (98, 0.75622714),\n",
       " (99, 0.4048996)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class W2VRetrievalModel(VectorSpaceRetrievalModel):\n",
    "    def __init__(self, doc_repr):\n",
    "        super().__init__(doc_repr)\n",
    "        \n",
    "        # the dimensionality of the vectors\n",
    "        self.size = 100 \n",
    "        self.min_count = 1\n",
    "    \n",
    "    def train_model(self):\n",
    "        \"\"\"\n",
    "        Trains the W2V model\n",
    "        \"\"\"\n",
    "        \n",
    "        model = Word2Vec(sentences=self.documents, size=self.size, min_count=self.min_count)\n",
    "        self.model = model\n",
    "        return model\n",
    "    \n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def vectorize_documents(self):\n",
    "        \"\"\"\n",
    "            Returns a doc_id -> vector dictionary\n",
    "        \"\"\"\n",
    "        \n",
    "        vectors = {}\n",
    "        \n",
    "        final_repr = list()\n",
    "        for doc_id, tok in self.doc_repr:\n",
    "            for word in tok:\n",
    "                if word in self.model.wv.vocab:\n",
    "                    vec = self.model.wv[word]\n",
    "                    final_repr.append(vec)\n",
    "                else:\n",
    "                    final_repr.append(np.zeros((self.size,)))\n",
    "            mean_vector = np.mean(np.array(final_repr),axis=0)\n",
    "            vectors[doc_id] = list(enumerate(mean_vector))\n",
    "        return vectors\n",
    "    \n",
    "        raise NotImplementedError()\n",
    "            \n",
    "    def vectorize_query(self, query):\n",
    "        \"\"\"\n",
    "        Vectorizes the query using the W2V model\n",
    "        \"\"\"\n",
    "        \n",
    "        query = process_text(query, **config_2)\n",
    "        final_repr = list()\n",
    "        for word in query:\n",
    "            if word in self.model.wv.vocab:\n",
    "                vec = self.model.wv[word]\n",
    "                \n",
    "                final_repr.append(vec)\n",
    "            else:\n",
    "                final_repr.append(np.zeros((self.size,)))\n",
    "        final_repr = np.mean(np.array(final_repr), axis=0)\n",
    "        \n",
    "    \n",
    "        return list(enumerate(final_repr))\n",
    "    \n",
    "        raise NotImplementedError()\n",
    "    \n",
    "class W2VPretrainedRetrievalModel(W2VRetrievalModel):\n",
    "    def __init__(self, doc_repr):\n",
    "        super().__init__(doc_repr)\n",
    "        self.model_name = \"word2vec-google-news-300\"\n",
    "        self.size = 300\n",
    "    \n",
    "    def train_model(self):\n",
    "        \"\"\"\n",
    "        Loads the pretrained model\n",
    "        \"\"\"\n",
    "        self.model = g_downloader.load(self.model_name)\n",
    "\n",
    "w2v = W2VRetrievalModel(doc_repr_2)\n",
    "w2v.train_model()\n",
    "\n",
    "# you can now get a W2V vector for a given query in the following way:\n",
    "w2v.vectorize_query(\"report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:46:57.877640Z",
     "start_time": "2021-02-18T08:46:16.345675Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-18 09:46:16,347 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2021-02-18 09:46:16,494 : INFO : built Dictionary(5937 unique tokens: ['-', 'algebra', 'intern', 'languag', 'preliminari']...) from 3204 documents (total 115978 corpus positions)\n",
      "2021-02-18 09:46:16,502 : INFO : discarding 4740 tokens: [('repeat', 8), ('glossari', 7), ('inspect', 8), ('uncol', 2), ('rung', 9), ('secant', 2), ('.', 1603), ('acceler', 6), ('diverg', 3), ('induc', 9)]...\n",
      "2021-02-18 09:46:16,503 : INFO : keeping 1197 tokens which were in no less than 10 and no more than 1602 (=50.0%) documents\n",
      "2021-02-18 09:46:16,506 : INFO : resulting dictionary: Dictionary(1197 unique tokens: ['-', 'algebra', 'intern', 'languag', 'preliminari']...)\n",
      "2021-02-18 09:46:16,862 : INFO : loading projection weights from C:\\Users\\marta/gensim-data\\word2vec-google-news-300\\word2vec-google-news-300.gz\n",
      "2021-02-18 09:46:57,830 : INFO : loaded (3000000, 300) matrix from C:\\Users\\marta/gensim-data\\word2vec-google-news-300\\word2vec-google-news-300.gz\n",
      "<ipython-input-87-9aa5b93747f8>:47: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if word in self.model.wv.vocab:\n",
      "<ipython-input-87-9aa5b93747f8>:48: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  vec = self.model.wv[word]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, -0.14257812),\n",
       " (1, -0.1640625),\n",
       " (2, -0.09033203),\n",
       " (3, -0.11230469),\n",
       " (4, 0.100097656),\n",
       " (5, -0.041259766),\n",
       " (6, 0.048828125),\n",
       " (7, -0.13671875),\n",
       " (8, 0.19628906),\n",
       " (9, -0.13476562),\n",
       " (10, -0.017578125),\n",
       " (11, 0.032226562),\n",
       " (12, 0.095214844),\n",
       " (13, -0.10595703),\n",
       " (14, -0.16992188),\n",
       " (15, 0.041015625),\n",
       " (16, -0.26367188),\n",
       " (17, -0.0063171387),\n",
       " (18, -0.17773438),\n",
       " (19, -0.24023438),\n",
       " (20, 0.3515625),\n",
       " (21, -0.012207031),\n",
       " (22, -0.16210938),\n",
       " (23, -0.12060547),\n",
       " (24, 0.04321289),\n",
       " (25, 0.10986328),\n",
       " (26, 0.052490234),\n",
       " (27, 0.17871094),\n",
       " (28, -0.14550781),\n",
       " (29, 0.13769531),\n",
       " (30, -0.08203125),\n",
       " (31, -0.28320312),\n",
       " (32, -0.10888672),\n",
       " (33, -0.2890625),\n",
       " (34, 0.072265625),\n",
       " (35, -0.04736328),\n",
       " (36, 0.040283203),\n",
       " (37, 0.067871094),\n",
       " (38, 0.11669922),\n",
       " (39, 0.000831604),\n",
       " (40, 0.068359375),\n",
       " (41, 0.12011719),\n",
       " (42, -0.088378906),\n",
       " (43, 0.33789062),\n",
       " (44, -0.044677734),\n",
       " (45, -0.030151367),\n",
       " (46, 0.0076904297),\n",
       " (47, -0.021118164),\n",
       " (48, -0.25390625),\n",
       " (49, 0.14941406),\n",
       " (50, 0.3984375),\n",
       " (51, 0.021606445),\n",
       " (52, -0.02319336),\n",
       " (53, 0.0063476562),\n",
       " (54, 0.008239746),\n",
       " (55, -0.16894531),\n",
       " (56, 0.037353516),\n",
       " (57, -0.06347656),\n",
       " (58, 0.1171875),\n",
       " (59, -0.1484375),\n",
       " (60, -0.07861328),\n",
       " (61, 0.36914062),\n",
       " (62, -0.22460938),\n",
       " (63, 0.17382812),\n",
       " (64, 0.0138549805),\n",
       " (65, 0.1875),\n",
       " (66, -0.10107422),\n",
       " (67, 0.037841797),\n",
       " (68, 0.0021209717),\n",
       " (69, -0.05126953),\n",
       " (70, 0.096191406),\n",
       " (71, -0.057128906),\n",
       " (72, 0.10595703),\n",
       " (73, -0.020996094),\n",
       " (74, 0.16113281),\n",
       " (75, 0.09765625),\n",
       " (76, 0.038330078),\n",
       " (77, 0.21972656),\n",
       " (78, 0.10644531),\n",
       " (79, 0.0859375),\n",
       " (80, 0.1796875),\n",
       " (81, -0.08300781),\n",
       " (82, -0.033203125),\n",
       " (83, 0.041015625),\n",
       " (84, -0.064941406),\n",
       " (85, 0.019897461),\n",
       " (86, 0.13378906),\n",
       " (87, -0.09765625),\n",
       " (88, -0.19335938),\n",
       " (89, -0.23535156),\n",
       " (90, 0.19042969),\n",
       " (91, 0.0024871826),\n",
       " (92, -0.01574707),\n",
       " (93, 0.032226562),\n",
       " (94, -0.21972656),\n",
       " (95, -0.091308594),\n",
       " (96, 0.021240234),\n",
       " (97, 0.15820312),\n",
       " (98, 0.29882812),\n",
       " (99, -0.328125),\n",
       " (100, 0.057373047),\n",
       " (101, -0.04638672),\n",
       " (102, 0.11328125),\n",
       " (103, -0.1015625),\n",
       " (104, 0.18066406),\n",
       " (105, -0.025146484),\n",
       " (106, -0.16601562),\n",
       " (107, -0.096191406),\n",
       " (108, 0.018798828),\n",
       " (109, -0.19433594),\n",
       " (110, 0.14941406),\n",
       " (111, -0.056640625),\n",
       " (112, -0.106933594),\n",
       " (113, -0.15039062),\n",
       " (114, -0.17578125),\n",
       " (115, 0.11279297),\n",
       " (116, 0.049316406),\n",
       " (117, 0.21972656),\n",
       " (118, 0.31835938),\n",
       " (119, 0.15722656),\n",
       " (120, -0.29296875),\n",
       " (121, 0.10498047),\n",
       " (122, -0.296875),\n",
       " (123, -0.013427734),\n",
       " (124, 0.09082031),\n",
       " (125, 0.012573242),\n",
       " (126, -0.051513672),\n",
       " (127, -0.12890625),\n",
       " (128, 0.014465332),\n",
       " (129, 0.12060547),\n",
       " (130, -0.10107422),\n",
       " (131, -0.111328125),\n",
       " (132, 0.063964844),\n",
       " (133, -0.052978516),\n",
       " (134, -0.04321289),\n",
       " (135, -0.012939453),\n",
       " (136, -0.02758789),\n",
       " (137, -0.09716797),\n",
       " (138, -0.20214844),\n",
       " (139, 0.123046875),\n",
       " (140, -0.04248047),\n",
       " (141, 0.17382812),\n",
       " (142, -0.013671875),\n",
       " (143, 0.1015625),\n",
       " (144, -0.0009384155),\n",
       " (145, -0.03564453),\n",
       " (146, 0.30078125),\n",
       " (147, -0.068359375),\n",
       " (148, -0.056152344),\n",
       " (149, 0.037597656),\n",
       " (150, 0.06591797),\n",
       " (151, 0.040283203),\n",
       " (152, 0.0119018555),\n",
       " (153, 0.096191406),\n",
       " (154, 0.3671875),\n",
       " (155, -0.27929688),\n",
       " (156, -0.052001953),\n",
       " (157, -0.106933594),\n",
       " (158, -0.13476562),\n",
       " (159, -0.046142578),\n",
       " (160, 0.25),\n",
       " (161, 0.0056762695),\n",
       " (162, -0.014404297),\n",
       " (163, -0.03100586),\n",
       " (164, -0.060302734),\n",
       " (165, 0.10595703),\n",
       " (166, 0.37890625),\n",
       " (167, 0.05883789),\n",
       " (168, 0.123046875),\n",
       " (169, -0.115234375),\n",
       " (170, 0.14941406),\n",
       " (171, -0.1640625),\n",
       " (172, -0.23339844),\n",
       " (173, -0.07763672),\n",
       " (174, 0.026733398),\n",
       " (175, -0.021118164),\n",
       " (176, 0.19433594),\n",
       " (177, -0.056152344),\n",
       " (178, -0.006439209),\n",
       " (179, -0.16992188),\n",
       " (180, -0.118652344),\n",
       " (181, -0.06738281),\n",
       " (182, -0.068847656),\n",
       " (183, -0.08691406),\n",
       " (184, -0.1015625),\n",
       " (185, 0.014160156),\n",
       " (186, -0.20117188),\n",
       " (187, 0.09814453),\n",
       " (188, -0.010253906),\n",
       " (189, 0.1875),\n",
       " (190, 0.19628906),\n",
       " (191, -0.22070312),\n",
       " (192, -0.19628906),\n",
       " (193, -0.07373047),\n",
       " (194, 0.06640625),\n",
       " (195, -0.13378906),\n",
       " (196, 0.18359375),\n",
       " (197, -0.20019531),\n",
       " (198, 0.19824219),\n",
       " (199, 0.05029297),\n",
       " (200, 0.029907227),\n",
       " (201, 0.017700195),\n",
       " (202, -0.19335938),\n",
       " (203, -0.096191406),\n",
       " (204, -0.10253906),\n",
       " (205, 0.21289062),\n",
       " (206, -0.029907227),\n",
       " (207, 0.14355469),\n",
       " (208, 0.041015625),\n",
       " (209, -0.21191406),\n",
       " (210, 0.20800781),\n",
       " (211, 0.13769531),\n",
       " (212, -0.01965332),\n",
       " (213, 0.014953613),\n",
       " (214, -0.09765625),\n",
       " (215, 0.24316406),\n",
       " (216, 0.080078125),\n",
       " (217, 0.08251953),\n",
       " (218, 0.09863281),\n",
       " (219, 0.056884766),\n",
       " (220, 0.04248047),\n",
       " (221, 0.068847656),\n",
       " (222, -0.03540039),\n",
       " (223, -0.076171875),\n",
       " (224, -0.00016117096),\n",
       " (225, -0.07519531),\n",
       " (226, 0.22460938),\n",
       " (227, 0.15136719),\n",
       " (228, 0.10058594),\n",
       " (229, 0.10986328),\n",
       " (230, 0.023803711),\n",
       " (231, 0.088378906),\n",
       " (232, 0.061767578),\n",
       " (233, -0.107910156),\n",
       " (234, 0.06225586),\n",
       " (235, 0.0034332275),\n",
       " (236, 0.080566406),\n",
       " (237, 0.106933594),\n",
       " (238, 0.08886719),\n",
       " (239, -0.23730469),\n",
       " (240, 0.064941406),\n",
       " (241, 0.010192871),\n",
       " (242, -0.088378906),\n",
       " (243, -0.33203125),\n",
       " (244, 0.0046691895),\n",
       " (245, 0.21289062),\n",
       " (246, 0.0859375),\n",
       " (247, 0.020385742),\n",
       " (248, 0.045654297),\n",
       " (249, 0.1484375),\n",
       " (250, 0.11816406),\n",
       " (251, 0.055664062),\n",
       " (252, -0.17285156),\n",
       " (253, -0.125),\n",
       " (254, -0.025390625),\n",
       " (255, -0.31835938),\n",
       " (256, 0.03112793),\n",
       " (257, 0.0859375),\n",
       " (258, -0.041992188),\n",
       " (259, 0.15625),\n",
       " (260, 0.16113281),\n",
       " (261, 0.19824219),\n",
       " (262, -0.100097656),\n",
       " (263, 0.203125),\n",
       " (264, 0.12890625),\n",
       " (265, 0.23339844),\n",
       " (266, -0.26757812),\n",
       " (267, 0.05517578),\n",
       " (268, 0.048828125),\n",
       " (269, 0.072265625),\n",
       " (270, 0.24414062),\n",
       " (271, 0.24414062),\n",
       " (272, 0.056884766),\n",
       " (273, -0.0546875),\n",
       " (274, -0.033691406),\n",
       " (275, -0.12060547),\n",
       " (276, 0.03491211),\n",
       " (277, -0.14550781),\n",
       " (278, 0.087402344),\n",
       " (279, -0.08300781),\n",
       " (280, 0.017211914),\n",
       " (281, 0.14355469),\n",
       " (282, -0.122558594),\n",
       " (283, 0.1796875),\n",
       " (284, 0.13085938),\n",
       " (285, -0.16503906),\n",
       " (286, 0.012756348),\n",
       " (287, 0.16015625),\n",
       " (288, -0.03112793),\n",
       " (289, 0.08203125),\n",
       " (290, 0.17382812),\n",
       " (291, -0.16796875),\n",
       " (292, 0.13085938),\n",
       " (293, 0.08544922),\n",
       " (294, -0.2109375),\n",
       " (295, -0.13085938),\n",
       " (296, -0.028930664),\n",
       " (297, -0.10546875),\n",
       " (298, 0.084472656),\n",
       " (299, -0.14160156)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_pretrained = W2VPretrainedRetrievalModel(doc_repr_2)\n",
    "w2v_pretrained.train_model()\n",
    "\n",
    "# you can now get an W2V vector for a given query in the following way:\n",
    "w2v_pretrained.vectorize_query(\"report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:48:09.656452Z",
     "start_time": "2021-02-18T08:46:57.896589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1935fdded14b6cb153c53212ecaf8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Search Bar')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drm_w2v = DenseRetrievalRanker(w2v, cosine_sim)\n",
    "\n",
    "# test your LDA model\n",
    "search_fn = drm_w2v.search\n",
    "\n",
    "text = widgets.Text(description=\"Search Bar\", width=200)\n",
    "display(text)\n",
    "\n",
    "\n",
    "text.on_submit(handle_submit_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:51:12.570933Z",
     "start_time": "2021-02-18T08:48:09.658445Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-87-9aa5b93747f8>:29: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if word in self.model.wv.vocab:\n",
      "<ipython-input-87-9aa5b93747f8>:30: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  vec = self.model.wv[word]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9974d34cba940e3b0cfa89f28ed191e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Search Bar')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drm_w2v_pretrained = DenseRetrievalRanker(w2v_pretrained, cosine_sim)\n",
    "\n",
    "# test your LDA model\n",
    "search_fn = drm_w2v_pretrained.search\n",
    "\n",
    "text = widgets.Text(description=\"Search Bar\", width=200)\n",
    "display(text)\n",
    "\n",
    "\n",
    "text.on_submit(handle_submit_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:51:18.955245Z",
     "start_time": "2021-02-18T08:51:12.570933Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f60fdeb97febb7f4a6fd5bf109aac20",
     "grade": false,
     "grade_id": "cell-680facdcc98a19ab",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-18 09:51:12,577 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2021-02-18 09:51:12,716 : INFO : built Dictionary(5937 unique tokens: ['-', 'algebra', 'intern', 'languag', 'preliminari']...) from 3204 documents (total 115978 corpus positions)\n",
      "2021-02-18 09:51:12,723 : INFO : discarding 4740 tokens: [('repeat', 8), ('glossari', 7), ('inspect', 8), ('uncol', 2), ('rung', 9), ('secant', 2), ('.', 1603), ('acceler', 6), ('diverg', 3), ('induc', 9)]...\n",
      "2021-02-18 09:51:12,724 : INFO : keeping 1197 tokens which were in no less than 10 and no more than 1602 (=50.0%) documents\n",
      "2021-02-18 09:51:12,727 : INFO : resulting dictionary: Dictionary(1197 unique tokens: ['-', 'algebra', 'intern', 'languag', 'preliminari']...)\n",
      "2021-02-18 09:51:12,802 : INFO : collecting all words and their counts\n",
      "2021-02-18 09:51:12,802 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2021-02-18 09:51:12,827 : INFO : collected 5937 word types and 3205 unique tags from a corpus of 3204 examples and 115978 words\n",
      "2021-02-18 09:51:12,829 : INFO : Loading a fresh vocabulary\n",
      "2021-02-18 09:51:12,840 : INFO : effective_min_count=1 retains 5937 unique words (100% of original 5937, drops 0)\n",
      "2021-02-18 09:51:12,841 : INFO : effective_min_count=1 leaves 115978 word corpus (100% of original 115978, drops 0)\n",
      "2021-02-18 09:51:12,862 : INFO : deleting the raw counts dictionary of 5937 items\n",
      "2021-02-18 09:51:12,863 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2021-02-18 09:51:12,864 : INFO : downsampling leaves estimated 92353 word corpus (79.6% of prior 115978)\n",
      "2021-02-18 09:51:12,879 : INFO : estimated required memory for 5937 words and 100 dimensions: 9000100 bytes\n",
      "2021-02-18 09:51:12,879 : INFO : resetting layer weights\n",
      "2021-02-18 09:51:14,640 : INFO : training model with 3 workers on 5937 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-02-18 09:51:14,815 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-18 09:51:14,839 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-18 09:51:14,843 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-18 09:51:14,844 : INFO : EPOCH - 1 : training on 115978 raw words (95594 effective words) took 0.2s, 530080 effective words/s\n",
      "2021-02-18 09:51:15,025 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-18 09:51:15,031 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-18 09:51:15,038 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-18 09:51:15,038 : INFO : EPOCH - 2 : training on 115978 raw words (95468 effective words) took 0.2s, 500049 effective words/s\n",
      "2021-02-18 09:51:15,217 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-18 09:51:15,237 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-18 09:51:15,241 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-18 09:51:15,242 : INFO : EPOCH - 3 : training on 115978 raw words (95456 effective words) took 0.2s, 480473 effective words/s\n",
      "2021-02-18 09:51:15,437 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-18 09:51:15,447 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-18 09:51:15,455 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-18 09:51:15,456 : INFO : EPOCH - 4 : training on 115978 raw words (95499 effective words) took 0.2s, 451862 effective words/s\n",
      "2021-02-18 09:51:15,641 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-18 09:51:15,665 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-18 09:51:15,670 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-18 09:51:15,670 : INFO : EPOCH - 5 : training on 115978 raw words (95443 effective words) took 0.2s, 457245 effective words/s\n",
      "2021-02-18 09:51:15,867 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-18 09:51:15,883 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-18 09:51:15,893 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-18 09:51:15,894 : INFO : EPOCH - 6 : training on 115978 raw words (95566 effective words) took 0.2s, 436484 effective words/s\n",
      "2021-02-18 09:51:16,084 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-18 09:51:16,105 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-18 09:51:16,111 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-18 09:51:16,112 : INFO : EPOCH - 7 : training on 115978 raw words (95464 effective words) took 0.2s, 445802 effective words/s\n",
      "2021-02-18 09:51:16,305 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-18 09:51:16,323 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-18 09:51:16,335 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-18 09:51:16,335 : INFO : EPOCH - 8 : training on 115978 raw words (95617 effective words) took 0.2s, 438135 effective words/s\n",
      "2021-02-18 09:51:16,533 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-18 09:51:16,550 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-18 09:51:16,553 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-18 09:51:16,554 : INFO : EPOCH - 9 : training on 115978 raw words (95544 effective words) took 0.2s, 446962 effective words/s\n",
      "2021-02-18 09:51:16,749 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-18 09:51:16,761 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-18 09:51:16,772 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-18 09:51:16,773 : INFO : EPOCH - 10 : training on 115978 raw words (95598 effective words) took 0.2s, 446135 effective words/s\n",
      "2021-02-18 09:51:16,965 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-18 09:51:16,971 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-18 09:51:16,971 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-18 09:51:16,971 : INFO : EPOCH - 11 : training on 115978 raw words (95352 effective words) took 0.2s, 467577 effective words/s\n",
      "2021-02-18 09:51:17,184 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-18 09:51:17,184 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-18 09:51:17,199 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-18 09:51:17,199 : INFO : EPOCH - 12 : training on 115978 raw words (95453 effective words) took 0.2s, 444452 effective words/s\n",
      "2021-02-18 09:51:17,401 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-18 09:51:17,413 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-18 09:51:17,414 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-18 09:51:17,414 : INFO : EPOCH - 13 : training on 115978 raw words (95584 effective words) took 0.2s, 455664 effective words/s\n",
      "2021-02-18 09:51:17,618 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-18 09:51:17,630 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-18 09:51:17,637 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-18 09:51:17,637 : INFO : EPOCH - 14 : training on 115978 raw words (95485 effective words) took 0.2s, 451766 effective words/s\n",
      "2021-02-18 09:51:17,834 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-18 09:51:17,845 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-18 09:51:17,858 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-18 09:51:17,859 : INFO : EPOCH - 15 : training on 115978 raw words (95673 effective words) took 0.2s, 440555 effective words/s\n",
      "2021-02-18 09:51:18,053 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-18 09:51:18,068 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-18 09:51:18,083 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-18 09:51:18,083 : INFO : EPOCH - 16 : training on 115978 raw words (95650 effective words) took 0.2s, 433495 effective words/s\n",
      "2021-02-18 09:51:18,283 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-18 09:51:18,294 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-18 09:51:18,301 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-18 09:51:18,302 : INFO : EPOCH - 17 : training on 115978 raw words (95576 effective words) took 0.2s, 448061 effective words/s\n",
      "2021-02-18 09:51:18,502 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-18 09:51:18,521 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-18 09:51:18,529 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-18 09:51:18,529 : INFO : EPOCH - 18 : training on 115978 raw words (95529 effective words) took 0.2s, 427224 effective words/s\n",
      "2021-02-18 09:51:18,715 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-18 09:51:18,732 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-18 09:51:18,735 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-18 09:51:18,735 : INFO : EPOCH - 19 : training on 115978 raw words (95553 effective words) took 0.2s, 475025 effective words/s\n",
      "2021-02-18 09:51:18,908 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-18 09:51:18,934 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-18 09:51:18,938 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-18 09:51:18,938 : INFO : EPOCH - 20 : training on 115978 raw words (95549 effective words) took 0.2s, 481945 effective words/s\n",
      "2021-02-18 09:51:18,939 : INFO : training on a 2319560 raw words (1910653 effective words) took 4.3s, 445443 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 0.039129663),\n",
       " (1, 0.06380455),\n",
       " (2, 0.0372417),\n",
       " (3, -0.066919826),\n",
       " (4, 0.029172387),\n",
       " (5, 0.043593843),\n",
       " (6, -0.07972468),\n",
       " (7, -0.006866838),\n",
       " (8, -0.029241165),\n",
       " (9, 0.04472167),\n",
       " (10, 0.007805907),\n",
       " (11, -0.02276804),\n",
       " (12, -0.012108639),\n",
       " (13, -0.0821464),\n",
       " (14, 0.06447723),\n",
       " (15, -0.047652494),\n",
       " (16, 0.067281485),\n",
       " (17, -0.018826548),\n",
       " (18, 0.09013158),\n",
       " (19, -0.038388304),\n",
       " (20, 0.04685946),\n",
       " (21, -0.03749524),\n",
       " (22, -0.050237402),\n",
       " (23, 0.043843053),\n",
       " (24, -0.018520087),\n",
       " (25, 0.15471224),\n",
       " (26, 0.05769825),\n",
       " (27, -0.036037397),\n",
       " (28, 0.06086186),\n",
       " (29, 0.08397715),\n",
       " (30, -0.08648466),\n",
       " (31, 0.058906913),\n",
       " (32, 0.06772328),\n",
       " (33, -0.011261158),\n",
       " (34, -0.009952199),\n",
       " (35, -0.0033186167),\n",
       " (36, -0.056504942),\n",
       " (37, -0.054663632),\n",
       " (38, 0.042858183),\n",
       " (39, 0.10614691),\n",
       " (40, 0.030201562),\n",
       " (41, -0.025412027),\n",
       " (42, -0.006855831),\n",
       " (43, -0.06881432),\n",
       " (44, 0.015810946),\n",
       " (45, -0.054090057),\n",
       " (46, 0.088405214),\n",
       " (47, -0.03807256),\n",
       " (48, 0.13304307),\n",
       " (49, -0.035028167),\n",
       " (50, 0.028044464),\n",
       " (51, 0.026773695),\n",
       " (52, -0.026300121),\n",
       " (53, 0.030995699),\n",
       " (54, 0.06652481),\n",
       " (55, 0.0047106002),\n",
       " (56, -0.023302313),\n",
       " (57, 0.034355115),\n",
       " (58, 0.060992267),\n",
       " (59, -0.06492762),\n",
       " (60, 0.048114892),\n",
       " (61, -0.112234585),\n",
       " (62, -0.0005814653),\n",
       " (63, -0.014774057),\n",
       " (64, 0.021622112),\n",
       " (65, -0.013831952),\n",
       " (66, -0.040982813),\n",
       " (67, -0.06990617),\n",
       " (68, -0.050360892),\n",
       " (69, -0.054096308),\n",
       " (70, 0.016015965),\n",
       " (71, 0.06123679),\n",
       " (72, -0.056127034),\n",
       " (73, -0.072999954),\n",
       " (74, -0.04938703),\n",
       " (75, 0.0800327),\n",
       " (76, -0.04238491),\n",
       " (77, -0.026824946),\n",
       " (78, 0.0067367153),\n",
       " (79, -0.022722807),\n",
       " (80, -0.0132485125),\n",
       " (81, -0.06629803),\n",
       " (82, -0.0027044038),\n",
       " (83, 0.10700216),\n",
       " (84, -0.068378106),\n",
       " (85, 0.04271313),\n",
       " (86, 0.027894672),\n",
       " (87, -0.026299806),\n",
       " (88, -0.073968776),\n",
       " (89, 0.016280694),\n",
       " (90, -0.0653638),\n",
       " (91, -0.00492025),\n",
       " (92, 0.0074912724),\n",
       " (93, 0.043905795),\n",
       " (94, 0.08879455),\n",
       " (95, 0.0059225885),\n",
       " (96, 0.062235534),\n",
       " (97, 0.033231266),\n",
       " (98, 0.085916124),\n",
       " (99, 0.00044983145)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class D2VRetrievalModel(VectorSpaceRetrievalModel):\n",
    "    def __init__(self, doc_repr):\n",
    "        super().__init__(doc_repr)\n",
    "        \n",
    "        self.vector_size= 100\n",
    "        self.min_count = 1\n",
    "        self.epochs = 20\n",
    "        \n",
    "        \n",
    "        self.tags = [TaggedDocument(doc, [i]) for i, doc in self.doc_repr]\n",
    "        self.model = None\n",
    "        \n",
    "        \n",
    "    def train_model(self):\n",
    "        \n",
    "        model = Doc2Vec(self.tags, vector_size=self.vector_size, min_count=self.min_count, epochs=self.epochs)\n",
    "        self.model = model\n",
    "        return model\n",
    "    \n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def vectorize_documents(self):\n",
    "        \"\"\"\n",
    "            Returns a doc_id -> vector dictionary\n",
    "        \"\"\"\n",
    "        \n",
    "        vectors = {}\n",
    "        for doc_id, tok in self.doc_repr:\n",
    "            vectors[doc_id] = list(enumerate(self.model.infer_vector(tok)))\n",
    "        return vectors\n",
    "        \n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def vectorize_query(self, query):\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        query = process_text(query, **config_2)\n",
    "        return list(enumerate(self.model.infer_vector(query)))\n",
    "    \n",
    "        raise NotImplementedError()\n",
    "        \n",
    "d2v = D2VRetrievalModel(doc_repr_2)\n",
    "d2v.train_model()\n",
    "\n",
    "\n",
    "# # you can now get an LSI vector for a given query in the following way:\n",
    "d2v.vectorize_query(\"report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:51:23.334513Z",
     "start_time": "2021-02-18T08:51:18.972200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d421a1d66ae147029605891a7251df9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Search Bar')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drm_d2v = DenseRetrievalRanker(d2v, cosine_sim)\n",
    "\n",
    "# test your LDA model\n",
    "search_fn = drm_d2v.search\n",
    "\n",
    "text = widgets.Text(description=\"Search Bar\", width=200)\n",
    "display(text)\n",
    "\n",
    "\n",
    "text.on_submit(handle_submit_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "363ec36c1d03d9f9e1c2045a6e193c14",
     "grade": false,
     "grade_id": "cell-3529ae29eece7b97",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "## Section 9: Re-ranking <a class=\"anchor\" id=\"reranking\"></a>\n",
    "\n",
    "[Back to Part 2](#part2)\n",
    "\n",
    "To motivate the re-ranking perspective (i.e retrieve with lexical method + rerank with a semantic method), let's search using semantic methods and compare it to BM25's performance, along with their runtime:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae398da0a8c23c95bcbb0023b7ec6f34",
     "grade": false,
     "grade_id": "cell-db5ff09f97841af7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "Re-ranking involves retrieving a small set of documents using simple but fast methods like BM25 and then re-ranking them with the aid of semantic methods such as LDA or LSI. This not only makes retrieval faster, but semantic methods perform poorly when used in isolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T08:51:55.262841Z",
     "start_time": "2021-02-18T08:51:55.249875Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63b6b05a676a2ae3f08d8bed1bc59428",
     "grade": false,
     "grade_id": "cell-5bf47600d1a0c507",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class DenseRerankingModel:\n",
    "    def __init__(self, initial_retrieval_fn, vsrm, similarity_fn):\n",
    "        self.ret = initial_retrieval_fn\n",
    "        self.vsrm = vsrm\n",
    "        self.similarity_fn = similarity_fn\n",
    "        self.vectorized_documents = vsrm.vectorize_documents()\n",
    "        \n",
    "        assert len(self.vectorized_documents) == len(doc_repr_2)\n",
    "    \n",
    "    def search(self, query, K=50):\n",
    "        \n",
    "        initial_list = self.ret(query)[:K]\n",
    "        query = self.vsrm.vectorize_query(query)\n",
    "        list_scores = list()\n",
    "        for doc_id, _ in initial_list:\n",
    "            doc_vec = self.vectorized_documents[doc_id]\n",
    "            score = self.similarity_fn(query, doc_vec)\n",
    "            list_scores.append((doc_id, score))\n",
    "        list_scores.sort(key=lambda _:-_[1])\n",
    "        return list_scores\n",
    "    \n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
